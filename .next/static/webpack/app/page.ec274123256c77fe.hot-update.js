"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
self["webpackHotUpdate_N_E"]("app/page",{

/***/ "(app-pages-browser)/./.contentlayer/generated/Blog/bert__index.mdx.json":
/*!***********************************************************!*\
  !*** ./.contentlayer/generated/Blog/bert__index.mdx.json ***!
  \***********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

module.exports = JSON.parse('{"title":"BERT (Bidirectional Encoder Representations from Transformers)","publishedAt":"2024-07-10T00:00:00.000Z","updatedAt":"2024-07-10T00:00:00.000Z","description":"BERT (Bidirectional Encoder Representations from Transformers) is a deep learning model that improves natural language understanding by pre-training on vast amounts of text to capture context from both directions.","image":{"filePath":"../public/blogs/bert/screenshot.png","relativeFilePath":"../../public/blogs/bert/screenshot.png","format":"png","height":1348,"width":2386,"aspectRatio":1.7700296735905046,"blurhashDataUrl":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAJFBMVEXj4+To6Of39/fu7ey+zN/+/f3i4ODW2eDXzsnb19XByM3J1N1lIvkRAAAACXBIWXMAABYlAAAWJQFJUiTwAAAANUlEQVR4nC3ByQHAMAwCMMD4zP779lMJUUosA3bLtnGv5XuHmUrsLLoiI1iAMiURvwJJBskPKr8A+mFPeg8AAAAASUVORK5CYII="},"isPublished":true,"author":"junbrro","tags":["Deep Learning"],"body":{"raw":"\\n# Introduction\\n\\n- **Importance of Bidirectional Pre-training**\\n  - **Contextual Background**: Unlike previous models which were largely unidirectional, BERT leverages context from both directions, significantly enhancing language comprehension.\\n  - **MLM (Masked Language Model)**: Randomly masks some words and predicts these masked words based solely on their context, enabling effective bidirectional training.\\n- **Novel Pre-training Objectives**\\n  - **Next Sentence Prediction (NSP)**: Predicts whether two sentences logically follow each other, enhancing the model\'s understanding of sentence relationships. This is particularly beneficial for tasks like Question Answering (QA) and Natural Language Inference (NLI).\\n- **Simplification and Enhancement of Fine-tuning**\\n  - BERT provides a universal language model that can be finely adjusted for a wide range of NLP tasks, achieving high performance without the need for many task-specific architectures.\\n\\n# Related Work\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/6d596cd3-bce5-44a3-95c9-de4007f2d2bb)\\n\\n## Unsupervised Feature-based Approaches\\n\\n- **Evolution from Non-neural to Neural Methods**: The journey from early non-neural approaches to advanced neural embeddings marks a significant advancement in creating effective word representations.\\n- **Pre-trained Embeddings\' Impact**: Pre-trained word embeddings, developed through various pre-training objectives, have become essential, significantly enhancing NLP system performances over scratch-learned embeddings.\\n- **Extension to Sentence and Paragraph Embeddings**: The field has expanded to include embeddings for larger text units like sentences and paragraphs, employing innovative training objectives to capture broader context.\\n\\n### **Embeddings from Language Model (**ELMO)\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/195d4ba1-38eb-41dd-b6cc-20bbc89073c1)\\nIf words with the same notation can be word-embedded differently depending on the context, the performance of natural language processing can be improved. The idea of taking context into account when embedding words is called Contextualized Word Embedding.\\n\\n- **Bi-LSTM**: A bidirectional long-term short-term memory network that reads text forward and backward to understand context in both directions, improving comprehension and prediction accuracy in tasks such as text analysis.\\n- **BiLM**: A bidirectional language model that improves word representation by considering the context of the surrounding text, and is the basis for ELMo by providing rich and contextualized word embeddings.\\n\\n## Unsupervised Fine-tuning Approaches\\n\\nInitial research in feature-based methods concentrated on pre-training word embeddings using unlabeled text. Recently, the focus has shifted to pre-training encoders for generating contextual representations of tokens within sentences or documents, followed by fine-tuning for specific tasks. This method is advantageous because **it minimizes the number of parameters needed to be learned from scratch.**\\n\\n## Transfer Learning from Supervised Data\\n\\nStudies have shown the effectiveness of transfer learning from large-scale datasets in tasks like machine translation and natural language inference (NLI). This approach has been emphasized not only in NLP but also in CV, where models pre-trained on datasets like ImageNet are known to perform well when fine-tuned.\\n\\n# Bidirectional Encoder Representations from Transformers (BERT)\\n\\n## Model Architecture\\n\\n- BERT utilizes a multi-layer bidirectional Transformer encoder, following the design outlined by Vaswani et al. (2017). Its implementation closely mirrors the original, as described in the tensor2tensor library.\\n- Due to the widespread adoption of Transformers and the similarity of BERT\'s implementation to the original, a detailed description of the architecture is omitted, with references recommended to Vaswani et al. (2017) and resources like “The Annotated Transformer.”\\n- **Configuration Details**:\\n  - **BERTBASE**:\\n    - Layers (L): 12\\n    - Hidden Size (H): 768\\n    - Self-Attention Heads (A): 12\\n    - Total Parameters: 110M\\n  - **BERTLARGE**:\\n    - Layers (L): 24\\n    - Hidden Size (H): 1024\\n    - Self-Attention Heads (A): 16\\n    - Total Parameters: 340M\\n- **Model Size Parity**: BERTBASE\'s design mirrors that of OpenAI GPT to facilitate direct comparisons.\\n- **Self-Attention Mechanism Difference**: BERT uses bidirectional self-attention, enabling tokens to attend to the entire input sequence, contrasting with GPT’s unidirectional approach that limits attention to preceding tokens.\\n\\n## Input/Output Representations\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/149df631-08a9-45bb-8664-6b968ae05b3d)\\n\\n- **[CLS] Token**: Every input sequence begins with a [CLS] token. The final hidden state corresponding to this token aggregates sequence representations for classification tasks.\\n- **Sentence Pairs**: Input sequences can comprise a pair of sentences, separated by a [SEP] token. This structure is used for tasks involving sentence relationships.\\n- **Segment Embeddings**: To distinguish between the two sentences in a pair, segment embeddings are applied, labeling sentences as either \\"A\\" or \\"B.\\"\\n- **Token Embeddings**: BERT employs WordPiece embeddings to represent individual tokens within the input.\\n- **Position Embeddings**: Follows the same approach as used in the Transformer model to account for the position of each token within the sequence.\\n- **Input Representation**: The final input representation is a combination of the corresponding token, segment, and position embeddings for each token in the input.\\n\\n## Pre-training BERT\\n\\n### Task #1 : Masked LM\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/d60468b8-066a-4bc8-a78d-a2b6c4dd7462)\\n\\nUnlike Denoising Auto Encoders, which reconstruct the entire input, BERT focuses solely on predicting [MASK] tokens.\\n\\n- **Mismatch Issue**: A mismatch between pre-training and fine-tuning arises because [MASK] tokens, used during pre-training, don\'t appear in the fine-tuning phase.\\n\\nTo mitigate this, additional strategies are applied to the 15% of tokens selected for masking:\\n\\n- **80% of the time**: The token is replaced with a [MASK] token. For example, \\"my dog is hairy\\" becomes \\"my dog is [MASK].\\"\\n- **10% of the time**: The token is replaced with a random word. For example, \\"my dog is hairy\\" might turn into \\"my dog is apple.\\"\\n- **10% of the time**: The token is left unchanged. For example, \\"my dog is hairy\\" stays as \\"my dog is hairy.\\"\\n\\n### Task #2 : Next Sentence Prediction (NSP)\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2faf8540-48b6-4f66-8b71-329d29c6a0e4)\\n\\nBERT uses Next Sentence Prediction (NSP) to learn sentence relationships, crucial for NLP tasks. It trains on sentence pairs, labeled as \\"IsNext\\" if they sequentially follow each other, or \\"NotNext\\" if unrelated.\\n\\n- **IsNext**: Input: \\"[CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] of milk [SEP]\\", Label: IsNext.\\n- **NotNext**: Input: \\"[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flightless birds [SEP]\\", Label: NotNext.\\n\\nThis approach enhances BERT\'s understanding of sentence context and relationships.\\n\\n### Pre-training Data\\n\\n_For the pre-training corpus we use the BooksCorpus (800M words) (Zhu et al., 2015) and English Wikipedia (2,500M words)._\\n\\n## Fine-tuning BERT\\n\\n- **Fine-tuning Flexibility**: BERT adapts to various NLP tasks by adjusting inputs and outputs, efficiently handling both single texts and text pairs.\\n- **Unified Encoding**: Leverages self-attention to process text pairs, offering integrated bidirectional cross attention, simplifying the encoding process.\\n- **Task Adaptation**: Directly integrates task-specific inputs and outputs, supporting a wide range of NLP tasks through end-to-end fine-tuning.\\n- **Efficient Process**: Achieves results within an hour on a Cloud TPU or a few hours on a GPU, demonstrating fine-tuning\'s cost-effectiveness.\\n- **Comprehensive Application**: Detailed task-specific applications and fine-tuning processes are documented, ensuring replicability and clarity.\\n\\n# Experiments\\n\\n## General Language Understanding Evaluation (GLUE)\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/1ff7afd6-95ac-4a22-80d6-6beb73f373a5)\\n\\n## Stanford Question Answering Dataset (SQuAD)\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/302b7ea4-4632-47d1-8d1b-ac9c4fed81ae)\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c9b917f5-8256-4175-b5c0-31f770f1e481)\\n\\n## Situations With Adversarial Generations (SWAG)\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/17453d5b-ae3f-475a-88c0-6c295b762ff4)\\n\\n# Ablation Studies\\n\\n## Effect of Pre-training Tasks\\n\\n### No NSP\\n\\n- Removing NSP from BERT\'s pre-training tasks showed a decrease in performance on downstream tasks, indicating NSP\'s role in improving understanding of sentence relationships.\\n\\n### LTR & No NSP\\n\\n- Adopting a left-to-right (LTR) model without the Next Sentence Prediction (NSP) task significantly diminishes performance on key NLP benchmarks, underscoring the vital role of NSP in understanding sentence relationships.\\n- Bidirectional models far outstrip LTR models in performance, particularly in tasks that require comprehensive context understanding, such as question answering.\\n- Attempts to improve LTR models with a BiLSTM layer yield some benefits but fail to reach the effectiveness of bidirectional models, illustrating the inherent limitations of LTR approaches.\\n- Despite considering separate LTR and RTL models to emulate bidirectionality, this strategy is deemed inefficient and less effective than a unified bidirectional model, highlighting BERT\'s optimized approach for superior performance across a range of NLP tasks.\\n\\n## Effect of Model Size\\n\\n- **Model size variation**: The paper also explores how changing the model size, including the number of layers (depth), the size of hidden layers, and the number of attention heads, impacts performance.\\n- **Larger models perform better**: It was found that larger models generally achieve better results on a range of NLP tasks, underscoring the trade-off between computational resources and performance. BERTLARGE, with more layers and a greater number of parameters, significantly outperformed smaller versions.\\n\\n## Feature-based Approach with BERT\\n\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/ca8c3a7d-1a63-4486-9ac3-c735b84df216)\\n![](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/92f047e5-73fa-42ac-af9b-ecd3c3e1a537)\\n","code":"var Component=(()=>{var sn=Object.create;var P=Object.defineProperty;var ln=Object.getOwnPropertyDescriptor;var cn=Object.getOwnPropertyNames;var mn=Object.getPrototypeOf,bn=Object.prototype.hasOwnProperty;var $=(l,e)=>()=>(e||l((e={exports:{}}).exports,e),e.exports),fn=(l,e)=>{for(var _ in e)P(l,_,{get:e[_],enumerable:!0})},xe=(l,e,_,y)=>{if(e&&typeof e==\\"object\\"||typeof e==\\"function\\")for(let N of cn(e))!bn.call(l,N)&&N!==_&&P(l,N,{get:()=>e[N],enumerable:!(y=ln(e,N))||y.enumerable});return l};var hn=(l,e,_)=>(_=l!=null?sn(mn(l)):{},xe(e||!l||!l.__esModule?P(_,\\"default\\",{value:l,enumerable:!0}):_,l)),_n=l=>xe(P({},\\"__esModule\\",{value:!0}),l);var ke=$((jn,je)=>{je.exports=React});var ve=$(z=>{\\"use strict\\";(function(){\\"use strict\\";var l=ke(),e=Symbol.for(\\"react.element\\"),_=Symbol.for(\\"react.portal\\"),y=Symbol.for(\\"react.fragment\\"),N=Symbol.for(\\"react.strict_mode\\"),q=Symbol.for(\\"react.profiler\\"),K=Symbol.for(\\"react.provider\\"),X=Symbol.for(\\"react.context\\"),G=Symbol.for(\\"react.forward_ref\\"),A=Symbol.for(\\"react.suspense\\"),C=Symbol.for(\\"react.suspense_list\\"),H=Symbol.for(\\"react.memo\\"),I=Symbol.for(\\"react.lazy\\"),He=Symbol.for(\\"react.offscreen\\"),Q=Symbol.iterator,Ee=\\"@@iterator\\";function we(n){if(n===null||typeof n!=\\"object\\")return null;var t=Q&&n[Q]||n[Ee];return typeof t==\\"function\\"?t:null}var j=l.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function b(n){{for(var t=arguments.length,i=new Array(t>1?t-1:0),o=1;o<t;o++)i[o-1]=arguments[o];Te(\\"error\\",n,i)}}function Te(n,t,i){{var o=j.ReactDebugCurrentFrame,d=o.getStackAddendum();d!==\\"\\"&&(t+=\\"%s\\",i=i.concat([d]));var s=i.map(function(a){return String(a)});s.unshift(\\"Warning: \\"+t),Function.prototype.apply.call(console[n],console,s)}}var Re=!1,Se=!1,Pe=!1,Ae=!1,Ce=!1,Z;Z=Symbol.for(\\"react.module.reference\\");function Ie(n){return!!(typeof n==\\"string\\"||typeof n==\\"function\\"||n===y||n===q||Ce||n===N||n===A||n===C||Ae||n===He||Re||Se||Pe||typeof n==\\"object\\"&&n!==null&&(n.$$typeof===I||n.$$typeof===H||n.$$typeof===K||n.$$typeof===X||n.$$typeof===G||n.$$typeof===Z||n.getModuleId!==void 0))}function Oe(n,t,i){var o=n.displayName;if(o)return o;var d=t.displayName||t.name||\\"\\";return d!==\\"\\"?i+\\"(\\"+d+\\")\\":i}function J(n){return n.displayName||\\"Context\\"}function p(n){if(n==null)return null;if(typeof n.tag==\\"number\\"&&b(\\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\\"),typeof n==\\"function\\")return n.displayName||n.name||null;if(typeof n==\\"string\\")return n;switch(n){case y:return\\"Fragment\\";case _:return\\"Portal\\";case q:return\\"Profiler\\";case N:return\\"StrictMode\\";case A:return\\"Suspense\\";case C:return\\"SuspenseList\\"}if(typeof n==\\"object\\")switch(n.$$typeof){case X:var t=n;return J(t)+\\".Consumer\\";case K:var i=n;return J(i._context)+\\".Provider\\";case G:return Oe(n,n.render,\\"ForwardRef\\");case H:var o=n.displayName||null;return o!==null?o:p(n.type)||\\"Memo\\";case I:{var d=n,s=d._payload,a=d._init;try{return p(a(s))}catch{return null}}}return null}var x=Object.assign,D=0,ee,ne,re,te,ie,oe,ue;function ae(){}ae.__reactDisabledLog=!0;function Le(){{if(D===0){ee=console.log,ne=console.info,re=console.warn,te=console.error,ie=console.group,oe=console.groupCollapsed,ue=console.groupEnd;var n={configurable:!0,enumerable:!0,value:ae,writable:!0};Object.defineProperties(console,{info:n,log:n,warn:n,error:n,group:n,groupCollapsed:n,groupEnd:n})}D++}}function Me(){{if(D--,D===0){var n={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:x({},n,{value:ee}),info:x({},n,{value:ne}),warn:x({},n,{value:re}),error:x({},n,{value:te}),group:x({},n,{value:ie}),groupCollapsed:x({},n,{value:oe}),groupEnd:x({},n,{value:ue})})}D<0&&b(\\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\\")}}var O=j.ReactCurrentDispatcher,L;function E(n,t,i){{if(L===void 0)try{throw Error()}catch(d){var o=d.stack.trim().match(/\\\\n( *(at )?)/);L=o&&o[1]||\\"\\"}return`\\n`+L+n}}var M=!1,w;{var Fe=typeof WeakMap==\\"function\\"?WeakMap:Map;w=new Fe}function de(n,t){if(!n||M)return\\"\\";{var i=w.get(n);if(i!==void 0)return i}var o;M=!0;var d=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var s;s=O.current,O.current=null,Le();try{if(t){var a=function(){throw Error()};if(Object.defineProperty(a.prototype,\\"props\\",{set:function(){throw Error()}}),typeof Reflect==\\"object\\"&&Reflect.construct){try{Reflect.construct(a,[])}catch(g){o=g}Reflect.construct(n,[],a)}else{try{a.call()}catch(g){o=g}n.call(a.prototype)}}else{try{throw Error()}catch(g){o=g}n()}}catch(g){if(g&&o&&typeof g.stack==\\"string\\"){for(var u=g.stack.split(`\\n`),f=o.stack.split(`\\n`),c=u.length-1,m=f.length-1;c>=1&&m>=0&&u[c]!==f[m];)m--;for(;c>=1&&m>=0;c--,m--)if(u[c]!==f[m]){if(c!==1||m!==1)do if(c--,m--,m<0||u[c]!==f[m]){var h=`\\n`+u[c].replace(\\" at new \\",\\" at \\");return n.displayName&&h.includes(\\"<anonymous>\\")&&(h=h.replace(\\"<anonymous>\\",n.displayName)),typeof n==\\"function\\"&&w.set(n,h),h}while(c>=1&&m>=0);break}}}finally{M=!1,O.current=s,Me(),Error.prepareStackTrace=d}var v=n?n.displayName||n.name:\\"\\",ye=v?E(v):\\"\\";return typeof n==\\"function\\"&&w.set(n,ye),ye}function Be(n,t,i){return de(n,!1)}function We(n){var t=n.prototype;return!!(t&&t.isReactComponent)}function T(n,t,i){if(n==null)return\\"\\";if(typeof n==\\"function\\")return de(n,We(n));if(typeof n==\\"string\\")return E(n);switch(n){case A:return E(\\"Suspense\\");case C:return E(\\"SuspenseList\\")}if(typeof n==\\"object\\")switch(n.$$typeof){case G:return Be(n.render);case H:return T(n.type,t,i);case I:{var o=n,d=o._payload,s=o._init;try{return T(s(d),t,i)}catch{}}}return\\"\\"}var R=Object.prototype.hasOwnProperty,se={},le=j.ReactDebugCurrentFrame;function S(n){if(n){var t=n._owner,i=T(n.type,n._source,t?t.type:null);le.setExtraStackFrame(i)}else le.setExtraStackFrame(null)}function Ve(n,t,i,o,d){{var s=Function.call.bind(R);for(var a in n)if(s(n,a)){var u=void 0;try{if(typeof n[a]!=\\"function\\"){var f=Error((o||\\"React class\\")+\\": \\"+i+\\" type `\\"+a+\\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\\"+typeof n[a]+\\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\\");throw f.name=\\"Invariant Violation\\",f}u=n[a](t,a,o,i,null,\\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\\")}catch(c){u=c}u&&!(u instanceof Error)&&(S(d),b(\\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\\",o||\\"React class\\",i,a,typeof u),S(null)),u instanceof Error&&!(u.message in se)&&(se[u.message]=!0,S(d),b(\\"Failed %s type: %s\\",i,u.message),S(null))}}}var Ye=Array.isArray;function F(n){return Ye(n)}function $e(n){{var t=typeof Symbol==\\"function\\"&&Symbol.toStringTag,i=t&&n[Symbol.toStringTag]||n.constructor.name||\\"Object\\";return i}}function ze(n){try{return ce(n),!1}catch{return!0}}function ce(n){return\\"\\"+n}function me(n){if(ze(n))return b(\\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\\",$e(n)),ce(n)}var U=j.ReactCurrentOwner,qe={key:!0,ref:!0,__self:!0,__source:!0},be,fe,B;B={};function Ke(n){if(R.call(n,\\"ref\\")){var t=Object.getOwnPropertyDescriptor(n,\\"ref\\").get;if(t&&t.isReactWarning)return!1}return n.ref!==void 0}function Xe(n){if(R.call(n,\\"key\\")){var t=Object.getOwnPropertyDescriptor(n,\\"key\\").get;if(t&&t.isReactWarning)return!1}return n.key!==void 0}function Qe(n,t){if(typeof n.ref==\\"string\\"&&U.current&&t&&U.current.stateNode!==t){var i=p(U.current.type);B[i]||(b(\'Component \\"%s\\" contains the string ref \\"%s\\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref\',p(U.current.type),n.ref),B[i]=!0)}}function Ze(n,t){{var i=function(){be||(be=!0,b(\\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",t))};i.isReactWarning=!0,Object.defineProperty(n,\\"key\\",{get:i,configurable:!0})}}function Je(n,t){{var i=function(){fe||(fe=!0,b(\\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",t))};i.isReactWarning=!0,Object.defineProperty(n,\\"ref\\",{get:i,configurable:!0})}}var en=function(n,t,i,o,d,s,a){var u={$$typeof:e,type:n,key:t,ref:i,props:a,_owner:s};return u._store={},Object.defineProperty(u._store,\\"validated\\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(u,\\"_self\\",{configurable:!1,enumerable:!1,writable:!1,value:o}),Object.defineProperty(u,\\"_source\\",{configurable:!1,enumerable:!1,writable:!1,value:d}),Object.freeze&&(Object.freeze(u.props),Object.freeze(u)),u};function nn(n,t,i,o,d){{var s,a={},u=null,f=null;i!==void 0&&(me(i),u=\\"\\"+i),Xe(t)&&(me(t.key),u=\\"\\"+t.key),Ke(t)&&(f=t.ref,Qe(t,d));for(s in t)R.call(t,s)&&!qe.hasOwnProperty(s)&&(a[s]=t[s]);if(n&&n.defaultProps){var c=n.defaultProps;for(s in c)a[s]===void 0&&(a[s]=c[s])}if(u||f){var m=typeof n==\\"function\\"?n.displayName||n.name||\\"Unknown\\":n;u&&Ze(a,m),f&&Je(a,m)}return en(n,u,f,d,o,U.current,a)}}var W=j.ReactCurrentOwner,he=j.ReactDebugCurrentFrame;function k(n){if(n){var t=n._owner,i=T(n.type,n._source,t?t.type:null);he.setExtraStackFrame(i)}else he.setExtraStackFrame(null)}var V;V=!1;function Y(n){return typeof n==\\"object\\"&&n!==null&&n.$$typeof===e}function _e(){{if(W.current){var n=p(W.current.type);if(n)return`\\n\\nCheck the render method of \\\\``+n+\\"`.\\"}return\\"\\"}}function rn(n){{if(n!==void 0){var t=n.fileName.replace(/^.*[\\\\\\\\\\\\/]/,\\"\\"),i=n.lineNumber;return`\\n\\nCheck your code at `+t+\\":\\"+i+\\".\\"}return\\"\\"}}var pe={};function tn(n){{var t=_e();if(!t){var i=typeof n==\\"string\\"?n:n.displayName||n.name;i&&(t=`\\n\\nCheck the top-level render call using <`+i+\\">.\\")}return t}}function ge(n,t){{if(!n._store||n._store.validated||n.key!=null)return;n._store.validated=!0;var i=tn(t);if(pe[i])return;pe[i]=!0;var o=\\"\\";n&&n._owner&&n._owner!==W.current&&(o=\\" It was passed a child from \\"+p(n._owner.type)+\\".\\"),k(n),b(\'Each child in a list should have a unique \\"key\\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.\',i,o),k(null)}}function Ne(n,t){{if(typeof n!=\\"object\\")return;if(F(n))for(var i=0;i<n.length;i++){var o=n[i];Y(o)&&ge(o,t)}else if(Y(n))n._store&&(n._store.validated=!0);else if(n){var d=we(n);if(typeof d==\\"function\\"&&d!==n.entries)for(var s=d.call(n),a;!(a=s.next()).done;)Y(a.value)&&ge(a.value,t)}}}function on(n){{var t=n.type;if(t==null||typeof t==\\"string\\")return;var i;if(typeof t==\\"function\\")i=t.propTypes;else if(typeof t==\\"object\\"&&(t.$$typeof===G||t.$$typeof===H))i=t.propTypes;else return;if(i){var o=p(t);Ve(i,n.props,\\"prop\\",o,n)}else if(t.PropTypes!==void 0&&!V){V=!0;var d=p(t);b(\\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\\",d||\\"Unknown\\")}typeof t.getDefaultProps==\\"function\\"&&!t.getDefaultProps.isReactClassApproved&&b(\\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\\")}}function un(n){{for(var t=Object.keys(n.props),i=0;i<t.length;i++){var o=t[i];if(o!==\\"children\\"&&o!==\\"key\\"){k(n),b(\\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\\",o),k(null);break}}n.ref!==null&&(k(n),b(\\"Invalid attribute `ref` supplied to `React.Fragment`.\\"),k(null))}}function an(n,t,i,o,d,s){{var a=Ie(n);if(!a){var u=\\"\\";(n===void 0||typeof n==\\"object\\"&&n!==null&&Object.keys(n).length===0)&&(u+=\\" You likely forgot to export your component from the file it\'s defined in, or you might have mixed up default and named imports.\\");var f=rn(d);f?u+=f:u+=_e();var c;n===null?c=\\"null\\":F(n)?c=\\"array\\":n!==void 0&&n.$$typeof===e?(c=\\"<\\"+(p(n.type)||\\"Unknown\\")+\\" />\\",u=\\" Did you accidentally export a JSX literal instead of a component?\\"):c=typeof n,b(\\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\\",c,u)}var m=nn(n,t,i,d,s);if(m==null)return m;if(a){var h=t.children;if(h!==void 0)if(o)if(F(h)){for(var v=0;v<h.length;v++)Ne(h[v],n);Object.freeze&&Object.freeze(h)}else b(\\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\\");else Ne(h,n)}return n===y?un(m):on(m),m}}var dn=an;z.Fragment=y,z.jsxDEV=dn})()});var Ue=$((vn,De)=>{\\"use strict\\";De.exports=ve()});var yn={};fn(yn,{default:()=>Nn,frontmatter:()=>pn});var r=hn(Ue()),pn={title:\\"BERT (Bidirectional Encoder Representations from Transformers)\\",description:\\"BERT (Bidirectional Encoder Representations from Transformers) is a deep learning model that improves natural language understanding by pre-training on vast amounts of text to capture context from both directions.\\",image:\\"../../public/blogs/bert/screenshot.png\\",publishedAt:\\"2024-07-10\\",updatedAt:\\"2024-07-10\\",author:\\"junbrro\\",isPublished:!0,tags:[\\"Deep Learning\\"]};function Ge(l){let e=Object.assign({h1:\\"h1\\",a:\\"a\\",span:\\"span\\",ul:\\"ul\\",li:\\"li\\",strong:\\"strong\\",p:\\"p\\",img:\\"img\\",h2:\\"h2\\",h3:\\"h3\\",em:\\"em\\"},l.components);return(0,r.jsxDEV)(r.Fragment,{children:[(0,r.jsxDEV)(e.h1,{id:\\"introduction\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#introduction\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Introduction\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:13,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Importance of Bidirectional Pre-training\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:15,columnNumber:3},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Contextual Background\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:16,columnNumber:5},this),\\": Unlike previous models which were largely unidirectional, BERT leverages context from both directions, significantly enhancing language comprehension.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:16,columnNumber:3},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"MLM (Masked Language Model)\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:17,columnNumber:5},this),\\": Randomly masks some words and predicts these masked words based solely on their context, enabling effective bidirectional training.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:17,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:16,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:15,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Novel Pre-training Objectives\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:18,columnNumber:3},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Next Sentence Prediction (NSP)\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:19,columnNumber:5},this),\\": Predicts whether two sentences logically follow each other, enhancing the model\'s understanding of sentence relationships. This is particularly beneficial for tasks like Question Answering (QA) and Natural Language Inference (NLI).\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:19,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:19,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:18,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Simplification and Enhancement of Fine-tuning\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:20,columnNumber:3},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:\\"BERT provides a universal language model that can be finely adjusted for a wide range of NLP tasks, achieving high performance without the need for many task-specific architectures.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:21,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:21,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:20,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:15,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h1,{id:\\"related-work\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#related-work\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Related Work\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:23,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/6d596cd3-bce5-44a3-95c9-de4007f2d2bb\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:25,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:25,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"unsupervised-feature-based-approaches\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#unsupervised-feature-based-approaches\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Unsupervised Feature-based Approaches\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:27,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Evolution from Non-neural to Neural Methods\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:29,columnNumber:3},this),\\": The journey from early non-neural approaches to advanced neural embeddings marks a significant advancement in creating effective word representations.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:29,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Pre-trained Embeddings\' Impact\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:30,columnNumber:3},this),\\": Pre-trained word embeddings, developed through various pre-training objectives, have become essential, significantly enhancing NLP system performances over scratch-learned embeddings.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:30,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Extension to Sentence and Paragraph Embeddings\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:31,columnNumber:3},this),\\": The field has expanded to include embeddings for larger text units like sentences and paragraphs, employing innovative training objectives to capture broader context.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:31,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:29,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h3,{id:\\"embeddings-from-language-model-elmo\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#embeddings-from-language-model-elmo\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"**Embeddings from Language Model (**ELMO)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:33,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:[(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/195d4ba1-38eb-41dd-b6cc-20bbc89073c1\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:35,columnNumber:1},this),`\\nIf words with the same notation can be word-embedded differently depending on the context, the performance of natural language processing can be improved. The idea of taking context into account when embedding words is called Contextualized Word Embedding.`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:35,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Bi-LSTM\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:38,columnNumber:3},this),\\": A bidirectional long-term short-term memory network that reads text forward and backward to understand context in both directions, improving comprehension and prediction accuracy in tasks such as text analysis.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:38,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"BiLM\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:39,columnNumber:3},this),\\": A bidirectional language model that improves word representation by considering the context of the surrounding text, and is the basis for ELMo by providing rich and contextualized word embeddings.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:39,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:38,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"unsupervised-fine-tuning-approaches\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#unsupervised-fine-tuning-approaches\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Unsupervised Fine-tuning Approaches\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:41,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:[\\"Initial research in feature-based methods concentrated on pre-training word embeddings using unlabeled text. Recently, the focus has shifted to pre-training encoders for generating contextual representations of tokens within sentences or documents, followed by fine-tuning for specific tasks. This method is advantageous because \\",(0,r.jsxDEV)(e.strong,{children:\\"it minimizes the number of parameters needed to be learned from scratch.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:43,columnNumber:330},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:43,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"transfer-learning-from-supervised-data\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#transfer-learning-from-supervised-data\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Transfer Learning from Supervised Data\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:45,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:\\"Studies have shown the effectiveness of transfer learning from large-scale datasets in tasks like machine translation and natural language inference (NLI). This approach has been emphasized not only in NLP but also in CV, where models pre-trained on datasets like ImageNet are known to perform well when fine-tuned.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:47,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h1,{id:\\"bidirectional-encoder-representations-from-transformers-bert\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#bidirectional-encoder-representations-from-transformers-bert\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Bidirectional Encoder Representations from Transformers (BERT)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:49,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"model-architecture\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#model-architecture\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Model Architecture\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:51,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:\\"BERT utilizes a multi-layer bidirectional Transformer encoder, following the design outlined by Vaswani et al. (2017). Its implementation closely mirrors the original, as described in the tensor2tensor library.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:53,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Due to the widespread adoption of Transformers and the similarity of BERT\'s implementation to the original, a detailed description of the architecture is omitted, with references recommended to Vaswani et al. (2017) and resources like \\\\u201CThe Annotated Transformer.\\\\u201D\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:54,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Configuration Details\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:55,columnNumber:3},this),\\":\\",`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"BERTBASE\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:56,columnNumber:5},this),\\":\\",`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Layers (L): 12\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:57,columnNumber:5},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Hidden Size (H): 768\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:58,columnNumber:5},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Self-Attention Heads (A): 12\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:59,columnNumber:5},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Total Parameters: 110M\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:60,columnNumber:5},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:57,columnNumber:5},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:56,columnNumber:3},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"BERTLARGE\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:61,columnNumber:5},this),\\":\\",`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Layers (L): 24\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:62,columnNumber:5},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Hidden Size (H): 1024\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:63,columnNumber:5},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Self-Attention Heads (A): 16\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:64,columnNumber:5},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Total Parameters: 340M\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:65,columnNumber:5},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:62,columnNumber:5},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:61,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:56,columnNumber:3},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:55,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Model Size Parity\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:66,columnNumber:3},this),\\": BERTBASE\'s design mirrors that of OpenAI GPT to facilitate direct comparisons.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:66,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Self-Attention Mechanism Difference\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:67,columnNumber:3},this),\\": BERT uses bidirectional self-attention, enabling tokens to attend to the entire input sequence, contrasting with GPT\\\\u2019s unidirectional approach that limits attention to preceding tokens.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:67,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:53,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"inputoutput-representations\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#inputoutput-representations\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Input/Output Representations\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:69,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/149df631-08a9-45bb-8664-6b968ae05b3d\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:71,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:71,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"[CLS] Token\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:73,columnNumber:3},this),\\": Every input sequence begins with a [CLS] token. The final hidden state corresponding to this token aggregates sequence representations for classification tasks.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:73,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Sentence Pairs\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:74,columnNumber:3},this),\\": Input sequences can comprise a pair of sentences, separated by a [SEP] token. This structure is used for tasks involving sentence relationships.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:74,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Segment Embeddings\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:75,columnNumber:3},this),\': To distinguish between the two sentences in a pair, segment embeddings are applied, labeling sentences as either \\"A\\" or \\"B.\\"\']},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:75,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Token Embeddings\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:76,columnNumber:3},this),\\": BERT employs WordPiece embeddings to represent individual tokens within the input.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:76,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Position Embeddings\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:77,columnNumber:3},this),\\": Follows the same approach as used in the Transformer model to account for the position of each token within the sequence.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:77,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Input Representation\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:78,columnNumber:3},this),\\": The final input representation is a combination of the corresponding token, segment, and position embeddings for each token in the input.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:78,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:73,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"pre-training-bert\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#pre-training-bert\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Pre-training BERT\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:80,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h3,{id:\\"task-1--masked-lm\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#task-1--masked-lm\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Task #1 : Masked LM\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:82,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/d60468b8-066a-4bc8-a78d-a2b6c4dd7462\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:84,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:84,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:\\"Unlike Denoising Auto Encoders, which reconstruct the entire input, BERT focuses solely on predicting [MASK] tokens.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:86,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Mismatch Issue\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:88,columnNumber:3},this),\\": A mismatch between pre-training and fine-tuning arises because [MASK] tokens, used during pre-training, don\'t appear in the fine-tuning phase.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:88,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:88,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:\\"To mitigate this, additional strategies are applied to the 15% of tokens selected for masking:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:90,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"80% of the time\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:92,columnNumber:3},this),\': The token is replaced with a [MASK] token. For example, \\"my dog is hairy\\" becomes \\"my dog is [MASK].\\"\']},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:92,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"10% of the time\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:93,columnNumber:3},this),\': The token is replaced with a random word. For example, \\"my dog is hairy\\" might turn into \\"my dog is apple.\\"\']},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:93,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"10% of the time\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:94,columnNumber:3},this),\': The token is left unchanged. For example, \\"my dog is hairy\\" stays as \\"my dog is hairy.\\"\']},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:94,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:92,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h3,{id:\\"task-2--next-sentence-prediction-nsp\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#task-2--next-sentence-prediction-nsp\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Task #2 : Next Sentence Prediction (NSP)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:96,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2faf8540-48b6-4f66-8b71-329d29c6a0e4\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:98,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:98,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:\'BERT uses Next Sentence Prediction (NSP) to learn sentence relationships, crucial for NLP tasks. It trains on sentence pairs, labeled as \\"IsNext\\" if they sequentially follow each other, or \\"NotNext\\" if unrelated.\'},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:100,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"IsNext\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:102,columnNumber:3},this),\': Input: \\"[CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] of milk [SEP]\\", Label: IsNext.\']},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:102,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"NotNext\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:103,columnNumber:3},this),\': Input: \\"[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flightless birds [SEP]\\", Label: NotNext.\']},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:103,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:102,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:\\"This approach enhances BERT\'s understanding of sentence context and relationships.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:105,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h3,{id:\\"pre-training-data\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#pre-training-data\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Pre-training Data\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:107,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:(0,r.jsxDEV)(e.em,{children:\\"For the pre-training corpus we use the BooksCorpus (800M words) (Zhu et al., 2015) and English Wikipedia (2,500M words).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:109,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:109,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"fine-tuning-bert\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#fine-tuning-bert\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Fine-tuning BERT\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:111,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Fine-tuning Flexibility\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:113,columnNumber:3},this),\\": BERT adapts to various NLP tasks by adjusting inputs and outputs, efficiently handling both single texts and text pairs.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:113,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Unified Encoding\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:114,columnNumber:3},this),\\": Leverages self-attention to process text pairs, offering integrated bidirectional cross attention, simplifying the encoding process.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:114,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Task Adaptation\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:115,columnNumber:3},this),\\": Directly integrates task-specific inputs and outputs, supporting a wide range of NLP tasks through end-to-end fine-tuning.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:115,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Efficient Process\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:116,columnNumber:3},this),\\": Achieves results within an hour on a Cloud TPU or a few hours on a GPU, demonstrating fine-tuning\'s cost-effectiveness.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:116,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Comprehensive Application\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:117,columnNumber:3},this),\\": Detailed task-specific applications and fine-tuning processes are documented, ensuring replicability and clarity.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:117,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:113,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h1,{id:\\"experiments\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#experiments\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Experiments\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:119,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"general-language-understanding-evaluation-glue\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#general-language-understanding-evaluation-glue\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"General Language Understanding Evaluation (GLUE)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:121,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/1ff7afd6-95ac-4a22-80d6-6beb73f373a5\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:123,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:123,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"stanford-question-answering-dataset-squad\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#stanford-question-answering-dataset-squad\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Stanford Question Answering Dataset (SQuAD)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:125,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:[(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/302b7ea4-4632-47d1-8d1b-ac9c4fed81ae\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:127,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c9b917f5-8256-4175-b5c0-31f770f1e481\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:128,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:127,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"situations-with-adversarial-generations-swag\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#situations-with-adversarial-generations-swag\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Situations With Adversarial Generations (SWAG)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:130,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/17453d5b-ae3f-475a-88c0-6c295b762ff4\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:132,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:132,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h1,{id:\\"ablation-studies\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#ablation-studies\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Ablation Studies\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:134,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"effect-of-pre-training-tasks\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#effect-of-pre-training-tasks\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Effect of Pre-training Tasks\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:136,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h3,{id:\\"no-nsp\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#no-nsp\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"No NSP\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:138,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Removing NSP from BERT\'s pre-training tasks showed a decrease in performance on downstream tasks, indicating NSP\'s role in improving understanding of sentence relationships.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:140,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:140,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h3,{id:\\"ltr--no-nsp\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#ltr--no-nsp\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"LTR & No NSP\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:142,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Adopting a left-to-right (LTR) model without the Next Sentence Prediction (NSP) task significantly diminishes performance on key NLP benchmarks, underscoring the vital role of NSP in understanding sentence relationships.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:144,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Bidirectional models far outstrip LTR models in performance, particularly in tasks that require comprehensive context understanding, such as question answering.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:145,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Attempts to improve LTR models with a BiLSTM layer yield some benefits but fail to reach the effectiveness of bidirectional models, illustrating the inherent limitations of LTR approaches.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:146,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:\\"Despite considering separate LTR and RTL models to emulate bidirectionality, this strategy is deemed inefficient and less effective than a unified bidirectional model, highlighting BERT\'s optimized approach for superior performance across a range of NLP tasks.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:147,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:144,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"effect-of-model-size\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#effect-of-model-size\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Effect of Model Size\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:149,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.ul,{children:[`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Model size variation\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:151,columnNumber:3},this),\\": The paper also explores how changing the model size, including the number of layers (depth), the size of hidden layers, and the number of attention heads, impacts performance.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:151,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\\"Larger models perform better\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:152,columnNumber:3},this),\\": It was found that larger models generally achieve better results on a range of NLP tasks, underscoring the trade-off between computational resources and performance. BERTLARGE, with more layers and a greater number of parameters, significantly outperformed smaller versions.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:152,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:151,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.h2,{id:\\"feature-based-approach-with-bert\\",children:[(0,r.jsxDEV)(e.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#feature-based-approach-with-bert\\",children:(0,r.jsxDEV)(e.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this),\\"Feature-based Approach with BERT\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:154,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.p,{children:[(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/ca8c3a7d-1a63-4486-9ac3-c735b84df216\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:156,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(e.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/92f047e5-73fa-42ac-af9b-ecd3c3e1a537\\",alt:\\"\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:157,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:156,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\",lineNumber:1,columnNumber:1},this)}function gn(l={}){let{wrapper:e}=l.components||{};return e?(0,r.jsxDEV)(e,Object.assign({},l,{children:(0,r.jsxDEV)(Ge,l,void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this)}),void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-de610790-7830-4c05-98a0-1a8764ce5b10.mdx\\"},this):Ge(l)}var Nn=gn;return _n(yn);})();\\n/*! Bundled license information:\\n\\nreact/cjs/react-jsx-dev-runtime.development.js:\\n  (**\\n   * @license React\\n   * react-jsx-dev-runtime.development.js\\n   *\\n   * Copyright (c) Facebook, Inc. and its affiliates.\\n   *\\n   * This source code is licensed under the MIT license found in the\\n   * LICENSE file in the root directory of this source tree.\\n   *)\\n*/\\n;return Component;"},"_id":"bert/index.mdx","_raw":{"sourceFilePath":"bert/index.mdx","sourceFileName":"index.mdx","sourceFileDir":"bert","contentType":"mdx","flattenedPath":"bert"},"type":"Blog","url":"/blogs/bert","readingTime":{"text":"7 min read","minutes":6.74,"time":404400,"words":1348},"toc":[{"level":"one","text":"Introduction","slug":"introduction"},{"level":"one","text":"Related Work","slug":"related-work"},{"level":"two","text":"Unsupervised Feature-based Approaches","slug":"unsupervised-feature-based-approaches"},{"level":"three","text":"**Embeddings from Language Model (**ELMO)","slug":"embeddings-from-language-model-elmo"},{"level":"two","text":"Unsupervised Fine-tuning Approaches","slug":"unsupervised-fine-tuning-approaches"},{"level":"two","text":"Transfer Learning from Supervised Data","slug":"transfer-learning-from-supervised-data"},{"level":"one","text":"Bidirectional Encoder Representations from Transformers (BERT)","slug":"bidirectional-encoder-representations-from-transformers-bert"},{"level":"two","text":"Model Architecture","slug":"model-architecture"},{"level":"two","text":"Input/Output Representations","slug":"inputoutput-representations"},{"level":"two","text":"Pre-training BERT","slug":"pre-training-bert"},{"level":"three","text":"Task #1 : Masked LM","slug":"task-1--masked-lm"},{"level":"three","text":"Task #2 : Next Sentence Prediction (NSP)","slug":"task-2--next-sentence-prediction-nsp"},{"level":"three","text":"Pre-training Data","slug":"pre-training-data"},{"level":"two","text":"Fine-tuning BERT","slug":"fine-tuning-bert"},{"level":"one","text":"Experiments","slug":"experiments"},{"level":"two","text":"General Language Understanding Evaluation (GLUE)","slug":"general-language-understanding-evaluation-glue"},{"level":"two","text":"Stanford Question Answering Dataset (SQuAD)","slug":"stanford-question-answering-dataset-squad"},{"level":"two","text":"Situations With Adversarial Generations (SWAG)","slug":"situations-with-adversarial-generations-swag"},{"level":"one","text":"Ablation Studies","slug":"ablation-studies"},{"level":"two","text":"Effect of Pre-training Tasks","slug":"effect-of-pre-training-tasks"},{"level":"three","text":"No NSP","slug":"no-nsp"},{"level":"three","text":"LTR & No NSP","slug":"ltr--no-nsp"},{"level":"two","text":"Effect of Model Size","slug":"effect-of-model-size"},{"level":"two","text":"Feature-based Approach with BERT","slug":"feature-based-approach-with-bert"}]}');

/***/ })

});
"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
self["webpackHotUpdate_N_E"]("app/page",{

/***/ "(app-pages-browser)/./.contentlayer/generated/Blog/vae__index.mdx.json":
/*!**********************************************************!*\
  !*** ./.contentlayer/generated/Blog/vae__index.mdx.json ***!
  \**********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

module.exports = JSON.parse('{"title":"[Paper Review] VAE (Variational Autoencoders)","publishedAt":"2024-07-13T00:00:00.000Z","updatedAt":"2024-07-13T00:00:00.000Z","description":"Variational Autoencoders (VAEs) employ a probabilistic approach to latent variable modeling, optimizing a variational lower bound to perform efficient approximate posterior inference and learning of generative models with continuous latent variables.","image":{"filePath":"../public/blogs/vae/screenshot.png","relativeFilePath":"../../public/blogs/vae/screenshot.png","format":"png","height":780,"width":1626,"aspectRatio":2.0846153846153848,"blurhashDataUrl":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAD1BMVEX+/v75+Pfy8PH87e3i4O9nI8m+AAAACXBIWXMAABYlAAAWJQFJUiTwAAAAKElEQVR4nE2JQQoAIACDdOv/b46iIi8OB494LSahq9iC37UZtmeyPQEGiwAv5U8KGQAAAABJRU5ErkJggg=="},"isPublished":true,"author":"junbrro","tags":["Deep Learning"],"body":{"raw":"\\nThis post is reviewing the VAE paper.\\n\\n### Citations\\n\\n[VAE : Auto-Encoding Variational Bayes - 논문 리뷰](https://velog.io/@lee9843/VAE-Auto-Encoding-Variational-Bayes-논문-리뷰)\\n\\nThumbnail image: [towardsdatascience](https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2)\\n\\n# Introduction\\n\\nHow can we perform efficient approximate inference and learning with directed probabilistic models whose continuous latent variables and/or parameters have intractable posterior distributions?\\n\\nThe answer lies in **Variational Bayesian** methods, which involve the optimization of approximations to intractable posterior probabilities.\\n\\n### Variational Bayesian (Appendix F)\\n\\nMarginal Likelihood: The combination of KL divergence and the lower bound.\\n\\n![Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fc4cbed7-6b60-40ea-a9c7-c5c9fdb4ba59)\\n\\n![Variational Lower Bound](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4edcf087-3b7e-4073-9063-b705bdbc8f99)\\n\\nVariational lower bound to the marginal likelihood:\\n\\n![Variational Lower Bound to Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/102829cb-e02d-49ce-bf67-f8da7b6058cd)\\n\\nMonte Carlo estimate of the variational lower bound:\\n\\n![Monte Carlo Estimate](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c9c61a64-253d-4607-acda-1466ca006569)\\n\\nFor more on [Variational Bayesian methods](https://en.wikipedia.org/wiki/Variational_Bayesian_methods).\\n\\n### Stochastic Gradient Variational Bayes (SGVB)\\n\\nThe **SGVB estimator** is a scalable estimator for variational inference that utilizes stochastic gradients, enabling optimization over large datasets. It facilitates efficient backpropagation through recognition models by approximating gradients, making it useful for efficient approximate posterior inference in almost any model with continuous latent variables and/or parameters.\\n\\n### Auto-Encoding Variational Bayes (AEVB)\\n\\nThe **AEVB algorithm** makes inference and learning particularly efficient by using the SGVB estimator to optimize a recognition model. This approach allows for very efficient approximate posterior inference using simple ancestral sampling, enabling the efficient learning of model parameters without the need for expensive iterative inference schemes like MCMC per datapoint.\\n\\n# Method\\n\\n![Method](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/5d0cf6c3-2880-428d-aec0-4512a9bc64ae)\\n\\n### Problem Scenario\\n\\nConsidering the dataset below:\\n\\n![Dataset Scenario](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4a64183e-7f05-4497-83bc-970973bfb694)\\n\\n1. The latent variable zi is generated from the prior distribution p_theta(z).\\n2. The dataset xi is generated from the conditional distribution p_theta(x|z).\\n\\n![Dataset Generation](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/e9a6c5fa-d805-425e-872c-f5675c77f4eb)\\n\\nThis approach addresses **intractability** (cannot compute marginal likelihood) and the challenge of **large datasets** (sampling should be conducted for each data point, which is costly for batch optimization).\\n\\nThe research proposes solutions for three problems:\\n\\n1. **Efficient approximate ML or MAP estimation** for the parameters theta. These parameters can be of interest themselves for analyzing natural processes and generating artificial data.\\n2. **Efficient approximate posterior inference** of the latent variable z given an observed value x for chosen parameters theta. This is useful for coding or data representation tasks.\\n3. **Efficient approximate marginal inference** of the variable x. This allows for various inference tasks where a prior over x is required, such as image denoising, inpainting, and super-resolution in computer vision.\\n\\nTo address these problems, the study introduces a recognition model q_theta(z|x) as an approximation to the intractable true posterior p_theta(z|x).\\n\\n### Method Summary\\n\\nThe recognition model parameters phi are learned together with the generative model parameters theta. Given a data point x, **a stochastic encoder** produces a distribution (e.g., Gaussian) of possible values for the code z that could generate x. **A stochastic decoder** p_theta(x|z) then produces a distribution of possible values of x given z.\\n\\n![Method Summary](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/019bf071-e7d3-4209-950e-6d160210b558)\\n\\n### The Variational Bound\\n\\nMarginal Likelihood log(p_theta(xi)):\\n\\n![Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/49db5dae-ee1f-45c4-8c91-85161c6b6b23)\\n\\nRight-hand side (RHS):\\n\\n1. KL divergence of the approximate from the true posterior (non-negative).\\n2. L(theta, phi; xi), the variational lower bound on the marginal likelihood of datapoint i.\\n\\n![RHS](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fb3ec5c3-f855-4c93-816e-3bf8b3a9a64d)\\n\\n![Variational Bound](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/60b1cc4f-2e9b-4ff9-b0e0-85d35c9252cb)\\n\\nThe objective is to differentiate and optimize the lower bound:\\n\\n![Optimization](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c243f655-27a7-4e8a-8e68-24756dd07c9e)\\n\\nThis corresponds to calculating the probability of x in Bayes\' theorem, known as the Evidence Lower Bound (ELBO). The loss function is derived from this ELBO.\\n\\n![ELBO](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/6470897e-6044-4b08-b888-eca7da3c6060)\\n\\n### The SGVB Estimator and AEVB Algorithm\\n\\n![SGVB Estimator](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fe40492d-7a49-4cac-ab79-2b049f529a8d)\\n\\n### Reparameterization Trick\\n\\n![Reparameterization Trick](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/a99833ee-ffb3-4001-b151-8025747cff67)\\n\\nTwo assumptions needed to compute regularization:\\n\\n1. The distribution of z that emerges from passing through the encoder, q_phi(z|x), follows a multivariate normal distribution with a diagonal covariance matrix.\\n2. The assumed distribution of z, the prior p(z), is that it follows a standard normal distribution with a mean of 0 and a standard deviation of 1.\\n\\nKLD ensures these assumptions are met and facilitates optimization.\\n\\n![KLD Assumptions](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/7f263752-d75d-46fd-be1b-6162b0bc9364)\\n\\nThus, the approach is differentiable, enabling the calculation of regularization.\\n\\n# Variational Auto-Encoder (VAE)\\n\\nThe variational approximate posterior is a multivariate Gaussian with a diagonal covariance structure.\\n\\n![VAE Gaussian](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/8f0c7e31-1e86-4efb-b6fe-4ad6a1f67a55)\\n\\nThe log-likelihood log(p_theta(xi | z^(i, l))) is modeled as a Bernoulli or Gaussian MLP, depending on the data type.\\n\\n### Appendix C: MLPs as Probabilistic Encoders and Decoders\\n\\n**Bernoulli MLP:**\\n\\n![Bernoulli MLP](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/45110c25-7f51-4e49-8a9b-ff277db35107)\\n![Bernoulli MLP Details](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2e849014-0a98-4e90-b443-8cfd5170e81f)\\n\\n---\\n\\n**Gaussian MLP:**\\n\\n![Gaussian MLP](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/bede1ba3-a3be-\\n\\n4d91-b61a-d7695a60ae50)\\n![Gaussian MLP Details](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/ffc15c2a-2085-4789-9a0c-9186e0755a60)\\n![Gaussian MLP](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2c1856a6-7090-473e-a357-11d2c57bc6cb)\\n![Gaussian MLP](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/eab9ee56-f060-4e74-9a85-3b893fc0d6e5)\\n\\n# Experiments\\n\\n### MNIST & Frey Face Datasets\\n\\n![Experiments](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/95d86097-c3a2-4450-9745-eb7691b54a28)\\n\\n### Likelihood Lower Bound\\n\\n### Marginal Likelihood\\n\\n![Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2ee19c13-08cb-484e-925d-2dfc15f95450)\\n\\n### Visualization of High-Dimensional Data\\n\\n# Conclusion & Future Work\\n\\nThe **SGVB estimator and AEVB algorithm** significantly improve variational inference for continuous latent variables, demonstrating theoretical advantages and experimental results.\\n\\nFuture work includes **investigating the use of SGVB and AEVB** in learning hierarchical generative models, particularly with deep neural networks such as convolutional networks for encoders and decoders. Additionally, **applying these methods to dynamic Bayesian networks** for modeling time-series data, extending the application of SGVB to optimize global parameters within models, and exploring supervised models that incorporate latent variables to learn complex noise distributions, enhancing model robustness and predictive performance.\\n","code":"var Component=(()=>{var ln=Object.create;var P=Object.defineProperty;var sn=Object.getOwnPropertyDescriptor;var bn=Object.getOwnPropertyNames;var cn=Object.getPrototypeOf,mn=Object.prototype.hasOwnProperty;var Y=(s,n)=>()=>(n||s((n={exports:{}}).exports,n),n.exports),fn=(s,n)=>{for(var p in n)P(s,p,{get:n[p],enumerable:!0})},xe=(s,n,p,N)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let y of bn(n))!mn.call(s,y)&&y!==p&&P(s,y,{get:()=>n[y],enumerable:!(N=sn(n,y))||N.enumerable});return s};var hn=(s,n,p)=>(p=s!=null?ln(cn(s)):{},xe(n||!s||!s.__esModule?P(p,\\"default\\",{value:s,enumerable:!0}):p,s)),pn=s=>xe(P({},\\"__esModule\\",{value:!0}),s);var ve=Y((jn,je)=>{je.exports=React});var ke=Y($=>{\\"use strict\\";(function(){\\"use strict\\";var s=ve(),n=Symbol.for(\\"react.element\\"),p=Symbol.for(\\"react.portal\\"),N=Symbol.for(\\"react.fragment\\"),y=Symbol.for(\\"react.strict_mode\\"),q=Symbol.for(\\"react.profiler\\"),K=Symbol.for(\\"react.provider\\"),X=Symbol.for(\\"react.context\\"),U=Symbol.for(\\"react.forward_ref\\"),S=Symbol.for(\\"react.suspense\\"),O=Symbol.for(\\"react.suspense_list\\"),H=Symbol.for(\\"react.memo\\"),A=Symbol.for(\\"react.lazy\\"),He=Symbol.for(\\"react.offscreen\\"),J=Symbol.iterator,Ee=\\"@@iterator\\";function we(e){if(e===null||typeof e!=\\"object\\")return null;var t=J&&e[J]||e[Ee];return typeof t==\\"function\\"?t:null}var j=s.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function m(e){{for(var t=arguments.length,i=new Array(t>1?t-1:0),o=1;o<t;o++)i[o-1]=arguments[o];Te(\\"error\\",e,i)}}function Te(e,t,i){{var o=j.ReactDebugCurrentFrame,d=o.getStackAddendum();d!==\\"\\"&&(t+=\\"%s\\",i=i.concat([d]));var l=i.map(function(u){return String(u)});l.unshift(\\"Warning: \\"+t),Function.prototype.apply.call(console[e],console,l)}}var Re=!1,Ce=!1,Pe=!1,Se=!1,Oe=!1,Z;Z=Symbol.for(\\"react.module.reference\\");function Ae(e){return!!(typeof e==\\"string\\"||typeof e==\\"function\\"||e===N||e===q||Oe||e===y||e===S||e===O||Se||e===He||Re||Ce||Pe||typeof e==\\"object\\"&&e!==null&&(e.$$typeof===A||e.$$typeof===H||e.$$typeof===K||e.$$typeof===X||e.$$typeof===U||e.$$typeof===Z||e.getModuleId!==void 0))}function Ve(e,t,i){var o=e.displayName;if(o)return o;var d=t.displayName||t.name||\\"\\";return d!==\\"\\"?i+\\"(\\"+d+\\")\\":i}function Q(e){return e.displayName||\\"Context\\"}function _(e){if(e==null)return null;if(typeof e.tag==\\"number\\"&&m(\\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\\"),typeof e==\\"function\\")return e.displayName||e.name||null;if(typeof e==\\"string\\")return e;switch(e){case N:return\\"Fragment\\";case p:return\\"Portal\\";case q:return\\"Profiler\\";case y:return\\"StrictMode\\";case S:return\\"Suspense\\";case O:return\\"SuspenseList\\"}if(typeof e==\\"object\\")switch(e.$$typeof){case X:var t=e;return Q(t)+\\".Consumer\\";case K:var i=e;return Q(i._context)+\\".Provider\\";case U:return Ve(e,e.render,\\"ForwardRef\\");case H:var o=e.displayName||null;return o!==null?o:_(e.type)||\\"Memo\\";case A:{var d=e,l=d._payload,u=d._init;try{return _(u(l))}catch{return null}}}return null}var x=Object.assign,D=0,ee,ne,re,te,ie,oe,ae;function ue(){}ue.__reactDisabledLog=!0;function Be(){{if(D===0){ee=console.log,ne=console.info,re=console.warn,te=console.error,ie=console.group,oe=console.groupCollapsed,ae=console.groupEnd;var e={configurable:!0,enumerable:!0,value:ue,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}D++}}function Le(){{if(D--,D===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:x({},e,{value:ee}),info:x({},e,{value:ne}),warn:x({},e,{value:re}),error:x({},e,{value:te}),group:x({},e,{value:ie}),groupCollapsed:x({},e,{value:oe}),groupEnd:x({},e,{value:ae})})}D<0&&m(\\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\\")}}var V=j.ReactCurrentDispatcher,B;function E(e,t,i){{if(B===void 0)try{throw Error()}catch(d){var o=d.stack.trim().match(/\\\\n( *(at )?)/);B=o&&o[1]||\\"\\"}return`\\n`+B+e}}var L=!1,w;{var Me=typeof WeakMap==\\"function\\"?WeakMap:Map;w=new Me}function de(e,t){if(!e||L)return\\"\\";{var i=w.get(e);if(i!==void 0)return i}var o;L=!0;var d=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var l;l=V.current,V.current=null,Be();try{if(t){var u=function(){throw Error()};if(Object.defineProperty(u.prototype,\\"props\\",{set:function(){throw Error()}}),typeof Reflect==\\"object\\"&&Reflect.construct){try{Reflect.construct(u,[])}catch(g){o=g}Reflect.construct(e,[],u)}else{try{u.call()}catch(g){o=g}e.call(u.prototype)}}else{try{throw Error()}catch(g){o=g}e()}}catch(g){if(g&&o&&typeof g.stack==\\"string\\"){for(var a=g.stack.split(`\\n`),f=o.stack.split(`\\n`),b=a.length-1,c=f.length-1;b>=1&&c>=0&&a[b]!==f[c];)c--;for(;b>=1&&c>=0;b--,c--)if(a[b]!==f[c]){if(b!==1||c!==1)do if(b--,c--,c<0||a[b]!==f[c]){var h=`\\n`+a[b].replace(\\" at new \\",\\" at \\");return e.displayName&&h.includes(\\"<anonymous>\\")&&(h=h.replace(\\"<anonymous>\\",e.displayName)),typeof e==\\"function\\"&&w.set(e,h),h}while(b>=1&&c>=0);break}}}finally{L=!1,V.current=l,Le(),Error.prepareStackTrace=d}var k=e?e.displayName||e.name:\\"\\",Ne=k?E(k):\\"\\";return typeof e==\\"function\\"&&w.set(e,Ne),Ne}function Ie(e,t,i){return de(e,!1)}function Fe(e){var t=e.prototype;return!!(t&&t.isReactComponent)}function T(e,t,i){if(e==null)return\\"\\";if(typeof e==\\"function\\")return de(e,Fe(e));if(typeof e==\\"string\\")return E(e);switch(e){case S:return E(\\"Suspense\\");case O:return E(\\"SuspenseList\\")}if(typeof e==\\"object\\")switch(e.$$typeof){case U:return Ie(e.render);case H:return T(e.type,t,i);case A:{var o=e,d=o._payload,l=o._init;try{return T(l(d),t,i)}catch{}}}return\\"\\"}var R=Object.prototype.hasOwnProperty,le={},se=j.ReactDebugCurrentFrame;function C(e){if(e){var t=e._owner,i=T(e.type,e._source,t?t.type:null);se.setExtraStackFrame(i)}else se.setExtraStackFrame(null)}function ze(e,t,i,o,d){{var l=Function.call.bind(R);for(var u in e)if(l(e,u)){var a=void 0;try{if(typeof e[u]!=\\"function\\"){var f=Error((o||\\"React class\\")+\\": \\"+i+\\" type `\\"+u+\\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\\"+typeof e[u]+\\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\\");throw f.name=\\"Invariant Violation\\",f}a=e[u](t,u,o,i,null,\\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\\")}catch(b){a=b}a&&!(a instanceof Error)&&(C(d),m(\\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\\",o||\\"React class\\",i,u,typeof a),C(null)),a instanceof Error&&!(a.message in le)&&(le[a.message]=!0,C(d),m(\\"Failed %s type: %s\\",i,a.message),C(null))}}}var We=Array.isArray;function M(e){return We(e)}function Ye(e){{var t=typeof Symbol==\\"function\\"&&Symbol.toStringTag,i=t&&e[Symbol.toStringTag]||e.constructor.name||\\"Object\\";return i}}function $e(e){try{return be(e),!1}catch{return!0}}function be(e){return\\"\\"+e}function ce(e){if($e(e))return m(\\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\\",Ye(e)),be(e)}var G=j.ReactCurrentOwner,qe={key:!0,ref:!0,__self:!0,__source:!0},me,fe,I;I={};function Ke(e){if(R.call(e,\\"ref\\")){var t=Object.getOwnPropertyDescriptor(e,\\"ref\\").get;if(t&&t.isReactWarning)return!1}return e.ref!==void 0}function Xe(e){if(R.call(e,\\"key\\")){var t=Object.getOwnPropertyDescriptor(e,\\"key\\").get;if(t&&t.isReactWarning)return!1}return e.key!==void 0}function Je(e,t){if(typeof e.ref==\\"string\\"&&G.current&&t&&G.current.stateNode!==t){var i=_(G.current.type);I[i]||(m(\'Component \\"%s\\" contains the string ref \\"%s\\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref\',_(G.current.type),e.ref),I[i]=!0)}}function Ze(e,t){{var i=function(){me||(me=!0,m(\\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",t))};i.isReactWarning=!0,Object.defineProperty(e,\\"key\\",{get:i,configurable:!0})}}function Qe(e,t){{var i=function(){fe||(fe=!0,m(\\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",t))};i.isReactWarning=!0,Object.defineProperty(e,\\"ref\\",{get:i,configurable:!0})}}var en=function(e,t,i,o,d,l,u){var a={$$typeof:n,type:e,key:t,ref:i,props:u,_owner:l};return a._store={},Object.defineProperty(a._store,\\"validated\\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(a,\\"_self\\",{configurable:!1,enumerable:!1,writable:!1,value:o}),Object.defineProperty(a,\\"_source\\",{configurable:!1,enumerable:!1,writable:!1,value:d}),Object.freeze&&(Object.freeze(a.props),Object.freeze(a)),a};function nn(e,t,i,o,d){{var l,u={},a=null,f=null;i!==void 0&&(ce(i),a=\\"\\"+i),Xe(t)&&(ce(t.key),a=\\"\\"+t.key),Ke(t)&&(f=t.ref,Je(t,d));for(l in t)R.call(t,l)&&!qe.hasOwnProperty(l)&&(u[l]=t[l]);if(e&&e.defaultProps){var b=e.defaultProps;for(l in b)u[l]===void 0&&(u[l]=b[l])}if(a||f){var c=typeof e==\\"function\\"?e.displayName||e.name||\\"Unknown\\":e;a&&Ze(u,c),f&&Qe(u,c)}return en(e,a,f,d,o,G.current,u)}}var F=j.ReactCurrentOwner,he=j.ReactDebugCurrentFrame;function v(e){if(e){var t=e._owner,i=T(e.type,e._source,t?t.type:null);he.setExtraStackFrame(i)}else he.setExtraStackFrame(null)}var z;z=!1;function W(e){return typeof e==\\"object\\"&&e!==null&&e.$$typeof===n}function pe(){{if(F.current){var e=_(F.current.type);if(e)return`\\n\\nCheck the render method of \\\\``+e+\\"`.\\"}return\\"\\"}}function rn(e){{if(e!==void 0){var t=e.fileName.replace(/^.*[\\\\\\\\\\\\/]/,\\"\\"),i=e.lineNumber;return`\\n\\nCheck your code at `+t+\\":\\"+i+\\".\\"}return\\"\\"}}var _e={};function tn(e){{var t=pe();if(!t){var i=typeof e==\\"string\\"?e:e.displayName||e.name;i&&(t=`\\n\\nCheck the top-level render call using <`+i+\\">.\\")}return t}}function ge(e,t){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var i=tn(t);if(_e[i])return;_e[i]=!0;var o=\\"\\";e&&e._owner&&e._owner!==F.current&&(o=\\" It was passed a child from \\"+_(e._owner.type)+\\".\\"),v(e),m(\'Each child in a list should have a unique \\"key\\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.\',i,o),v(null)}}function ye(e,t){{if(typeof e!=\\"object\\")return;if(M(e))for(var i=0;i<e.length;i++){var o=e[i];W(o)&&ge(o,t)}else if(W(e))e._store&&(e._store.validated=!0);else if(e){var d=we(e);if(typeof d==\\"function\\"&&d!==e.entries)for(var l=d.call(e),u;!(u=l.next()).done;)W(u.value)&&ge(u.value,t)}}}function on(e){{var t=e.type;if(t==null||typeof t==\\"string\\")return;var i;if(typeof t==\\"function\\")i=t.propTypes;else if(typeof t==\\"object\\"&&(t.$$typeof===U||t.$$typeof===H))i=t.propTypes;else return;if(i){var o=_(t);ze(i,e.props,\\"prop\\",o,e)}else if(t.PropTypes!==void 0&&!z){z=!0;var d=_(t);m(\\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\\",d||\\"Unknown\\")}typeof t.getDefaultProps==\\"function\\"&&!t.getDefaultProps.isReactClassApproved&&m(\\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\\")}}function an(e){{for(var t=Object.keys(e.props),i=0;i<t.length;i++){var o=t[i];if(o!==\\"children\\"&&o!==\\"key\\"){v(e),m(\\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\\",o),v(null);break}}e.ref!==null&&(v(e),m(\\"Invalid attribute `ref` supplied to `React.Fragment`.\\"),v(null))}}function un(e,t,i,o,d,l){{var u=Ae(e);if(!u){var a=\\"\\";(e===void 0||typeof e==\\"object\\"&&e!==null&&Object.keys(e).length===0)&&(a+=\\" You likely forgot to export your component from the file it\'s defined in, or you might have mixed up default and named imports.\\");var f=rn(d);f?a+=f:a+=pe();var b;e===null?b=\\"null\\":M(e)?b=\\"array\\":e!==void 0&&e.$$typeof===n?(b=\\"<\\"+(_(e.type)||\\"Unknown\\")+\\" />\\",a=\\" Did you accidentally export a JSX literal instead of a component?\\"):b=typeof e,m(\\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\\",b,a)}var c=nn(e,t,i,d,l);if(c==null)return c;if(u){var h=t.children;if(h!==void 0)if(o)if(M(h)){for(var k=0;k<h.length;k++)ye(h[k],e);Object.freeze&&Object.freeze(h)}else m(\\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\\");else ye(h,e)}return e===N?an(c):on(c),c}}var dn=un;$.Fragment=N,$.jsxDEV=dn})()});var Ge=Y((kn,De)=>{\\"use strict\\";De.exports=ke()});var Nn={};fn(Nn,{default:()=>yn,frontmatter:()=>_n});var r=hn(Ge()),_n={title:\\"[Paper Review] VAE (Variational Autoencoders)\\",description:\\"Variational Autoencoders (VAEs) employ a probabilistic approach to latent variable modeling, optimizing a variational lower bound to perform efficient approximate posterior inference and learning of generative models with continuous latent variables.\\",image:\\"../../public/blogs/vae/screenshot.png\\",publishedAt:\\"2024-07-13\\",updatedAt:\\"2024-07-13\\",author:\\"junbrro\\",isPublished:!0,tags:[\\"Deep Learning\\"]};function Ue(s){let n=Object.assign({p:\\"p\\",h3:\\"h3\\",a:\\"a\\",span:\\"span\\",h1:\\"h1\\",strong:\\"strong\\",img:\\"img\\",ol:\\"ol\\",li:\\"li\\",hr:\\"hr\\"},s.components);return(0,r.jsxDEV)(r.Fragment,{children:[(0,r.jsxDEV)(n.p,{children:\\"This post is reviewing the VAE paper.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:13,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"citations\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#citations\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Citations\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:15,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.a,{href:\\"https://velog.io/@lee9843/VAE-Auto-Encoding-Variational-Bayes-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0\\",children:\\"VAE : Auto-Encoding Variational Bayes - \\\\uB17C\\\\uBB38 \\\\uB9AC\\\\uBDF0\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:17,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:17,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"Thumbnail image: \\",(0,r.jsxDEV)(n.a,{href:\\"https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2\\",children:\\"towardsdatascience\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:19,columnNumber:18},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:19,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"introduction\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#introduction\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Introduction\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:21,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"How can we perform efficient approximate inference and learning with directed probabilistic models whose continuous latent variables and/or parameters have intractable posterior distributions?\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:23,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The answer lies in \\",(0,r.jsxDEV)(n.strong,{children:\\"Variational Bayesian\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:25,columnNumber:20},this),\\" methods, which involve the optimization of approximations to intractable posterior probabilities.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:25,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"variational-bayesian-appendix-f\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#variational-bayesian-appendix-f\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Variational Bayesian (Appendix F)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:27,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Marginal Likelihood: The combination of KL divergence and the lower bound.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:29,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fc4cbed7-6b60-40ea-a9c7-c5c9fdb4ba59\\",alt:\\"Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:31,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:31,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4edcf087-3b7e-4073-9063-b705bdbc8f99\\",alt:\\"Variational Lower Bound\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:33,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:33,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Variational lower bound to the marginal likelihood:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:35,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/102829cb-e02d-49ce-bf67-f8da7b6058cd\\",alt:\\"Variational Lower Bound to Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:37,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:37,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Monte Carlo estimate of the variational lower bound:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:39,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c9c61a64-253d-4607-acda-1466ca006569\\",alt:\\"Monte Carlo Estimate\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:41,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:41,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"For more on \\",(0,r.jsxDEV)(n.a,{href:\\"https://en.wikipedia.org/wiki/Variational_Bayesian_methods\\",children:\\"Variational Bayesian methods\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:43,columnNumber:13},this),\\".\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:43,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"stochastic-gradient-variational-bayes-sgvb\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#stochastic-gradient-variational-bayes-sgvb\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Stochastic Gradient Variational Bayes (SGVB)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:45,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The \\",(0,r.jsxDEV)(n.strong,{children:\\"SGVB estimator\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:47,columnNumber:5},this),\\" is a scalable estimator for variational inference that utilizes stochastic gradients, enabling optimization over large datasets. It facilitates efficient backpropagation through recognition models by approximating gradients, making it useful for efficient approximate posterior inference in almost any model with continuous latent variables and/or parameters.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:47,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"auto-encoding-variational-bayes-aevb\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#auto-encoding-variational-bayes-aevb\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Auto-Encoding Variational Bayes (AEVB)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:49,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The \\",(0,r.jsxDEV)(n.strong,{children:\\"AEVB algorithm\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:51,columnNumber:5},this),\\" makes inference and learning particularly efficient by using the SGVB estimator to optimize a recognition model. This approach allows for very efficient approximate posterior inference using simple ancestral sampling, enabling the efficient learning of model parameters without the need for expensive iterative inference schemes like MCMC per datapoint.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:51,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"method\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#method\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Method\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:53,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/5d0cf6c3-2880-428d-aec0-4512a9bc64ae\\",alt:\\"Method\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:55,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:55,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"problem-scenario\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#problem-scenario\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Problem Scenario\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:57,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Considering the dataset below:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:59,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4a64183e-7f05-4497-83bc-970973bfb694\\",alt:\\"Dataset Scenario\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:61,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:61,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The latent variable zi is generated from the prior distribution p_theta(z).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:63,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The dataset xi is generated from the conditional distribution p_theta(x|z).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:64,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:63,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/e9a6c5fa-d805-425e-872c-f5675c77f4eb\\",alt:\\"Dataset Generation\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:66,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:66,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"This approach addresses \\",(0,r.jsxDEV)(n.strong,{children:\\"intractability\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:68,columnNumber:25},this),\\" (cannot compute marginal likelihood) and the challenge of \\",(0,r.jsxDEV)(n.strong,{children:\\"large datasets\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:68,columnNumber:102},this),\\" (sampling should be conducted for each data point, which is costly for batch optimization).\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:68,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"The research proposes solutions for three problems:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:70,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Efficient approximate ML or MAP estimation\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:72,columnNumber:4},this),\\" for the parameters theta. These parameters can be of interest themselves for analyzing natural processes and generating artificial data.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:72,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Efficient approximate posterior inference\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:73,columnNumber:4},this),\\" of the latent variable z given an observed value x for chosen parameters theta. This is useful for coding or data representation tasks.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:73,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Efficient approximate marginal inference\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:74,columnNumber:4},this),\\" of the variable x. This allows for various inference tasks where a prior over x is required, such as image denoising, inpainting, and super-resolution in computer vision.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:74,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:72,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"To address these problems, the study introduces a recognition model q_theta(z|x) as an approximation to the intractable true posterior p_theta(z|x).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:76,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"method-summary\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#method-summary\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Method Summary\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:78,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The recognition model parameters phi are learned together with the generative model parameters theta. Given a data point x, \\",(0,r.jsxDEV)(n.strong,{children:\\"a stochastic encoder\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:80,columnNumber:125},this),\\" produces a distribution (e.g., Gaussian) of possible values for the code z that could generate x. \\",(0,r.jsxDEV)(n.strong,{children:\\"A stochastic decoder\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:80,columnNumber:248},this),\\" p_theta(x|z) then produces a distribution of possible values of x given z.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:80,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/019bf071-e7d3-4209-950e-6d160210b558\\",alt:\\"Method Summary\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:82,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:82,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"the-variational-bound\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#the-variational-bound\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"The Variational Bound\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:84,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Marginal Likelihood log(p_theta(xi)):\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:86,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/49db5dae-ee1f-45c4-8c91-85161c6b6b23\\",alt:\\"Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:88,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:88,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Right-hand side (RHS):\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:90,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:\\"KL divergence of the approximate from the true posterior (non-negative).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:92,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:\\"L(theta, phi; xi), the variational lower bound on the marginal likelihood of datapoint i.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:93,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:92,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fb3ec5c3-f855-4c93-816e-3bf8b3a9a64d\\",alt:\\"RHS\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:95,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:95,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/60b1cc4f-2e9b-4ff9-b0e0-85d35c9252cb\\",alt:\\"Variational Bound\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:97,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:97,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"The objective is to differentiate and optimize the lower bound:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:99,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c243f655-27a7-4e8a-8e68-24756dd07c9e\\",alt:\\"Optimization\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:101,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:101,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"This corresponds to calculating the probability of x in Bayes\' theorem, known as the Evidence Lower Bound (ELBO). The loss function is derived from this ELBO.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:103,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/6470897e-6044-4b08-b888-eca7da3c6060\\",alt:\\"ELBO\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:105,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:105,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"the-sgvb-estimator-and-aevb-algorithm\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#the-sgvb-estimator-and-aevb-algorithm\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"The SGVB Estimator and AEVB Algorithm\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:107,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fe40492d-7a49-4cac-ab79-2b049f529a8d\\",alt:\\"SGVB Estimator\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:109,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:109,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"reparameterization-trick\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#reparameterization-trick\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Reparameterization Trick\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:111,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/a99833ee-ffb3-4001-b151-8025747cff67\\",alt:\\"Reparameterization Trick\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:113,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:113,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Two assumptions needed to compute regularization:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:115,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The distribution of z that emerges from passing through the encoder, q_phi(z|x), follows a multivariate normal distribution with a diagonal covariance matrix.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:117,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The assumed distribution of z, the prior p(z), is that it follows a standard normal distribution with a mean of 0 and a standard deviation of 1.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:118,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:117,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"KLD ensures these assumptions are met and facilitates optimization.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:120,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/7f263752-d75d-46fd-be1b-6162b0bc9364\\",alt:\\"KLD Assumptions\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:122,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:122,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Thus, the approach is differentiable, enabling the calculation of regularization.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:124,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"variational-auto-encoder-vae\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#variational-auto-encoder-vae\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Variational Auto-Encoder (VAE)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:126,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"The variational approximate posterior is a multivariate Gaussian with a diagonal covariance structure.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:128,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/8f0c7e31-1e86-4efb-b6fe-4ad6a1f67a55\\",alt:\\"VAE Gaussian\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:130,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:130,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"The log-likelihood log(p_theta(xi | z^(i, l))) is modeled as a Bernoulli or Gaussian MLP, depending on the data type.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:132,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"appendix-c-mlps-as-probabilistic-encoders-and-decoders\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#appendix-c-mlps-as-probabilistic-encoders-and-decoders\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Appendix C: MLPs as Probabilistic Encoders and Decoders\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:134,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.strong,{children:\\"Bernoulli MLP:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:136,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:136,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/45110c25-7f51-4e49-8a9b-ff277db35107\\",alt:\\"Bernoulli MLP\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:138,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2e849014-0a98-4e90-b443-8cfd5170e81f\\",alt:\\"Bernoulli MLP Details\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:139,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:138,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.hr,{},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:141,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.strong,{children:\\"Gaussian MLP:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:143,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:143,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"![Gaussian MLP](\\",(0,r.jsxDEV)(n.a,{href:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/bede1ba3-a3be-\\",children:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/bede1ba3-a3be-\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:145,columnNumber:17},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:145,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[`4d91-b61a-d7695a60ae50)\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/ffc15c2a-2085-4789-9a0c-9186e0755a60\\",alt:\\"Gaussian MLP Details\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:148,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2c1856a6-7090-473e-a357-11d2c57bc6cb\\",alt:\\"Gaussian MLP\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:149,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/eab9ee56-f060-4e74-9a85-3b893fc0d6e5\\",alt:\\"Gaussian MLP\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:150,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:147,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"experiments\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#experiments\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Experiments\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:152,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"mnist--frey-face-datasets\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#mnist--frey-face-datasets\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"MNIST & Frey Face Datasets\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:154,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/95d86097-c3a2-4450-9745-eb7691b54a28\\",alt:\\"Experiments\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:156,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:156,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"likelihood-lower-bound\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#likelihood-lower-bound\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Likelihood Lower Bound\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:158,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"marginal-likelihood\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#marginal-likelihood\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Marginal Likelihood\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:160,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2ee19c13-08cb-484e-925d-2dfc15f95450\\",alt:\\"Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:162,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:162,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"visualization-of-high-dimensional-data\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#visualization-of-high-dimensional-data\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Visualization of High-Dimensional Data\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:164,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"conclusion--future-work\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#conclusion--future-work\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this),\\"Conclusion & Future Work\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:166,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The \\",(0,r.jsxDEV)(n.strong,{children:\\"SGVB estimator and AEVB algorithm\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:168,columnNumber:5},this),\\" significantly improve variational inference for continuous latent variables, demonstrating theoretical advantages and experimental results.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:168,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"Future work includes \\",(0,r.jsxDEV)(n.strong,{children:\\"investigating the use of SGVB and AEVB\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:170,columnNumber:22},this),\\" in learning hierarchical generative models, particularly with deep neural networks such as convolutional networks for encoders and decoders. Additionally, \\",(0,r.jsxDEV)(n.strong,{children:\\"applying these methods to dynamic Bayesian networks\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:170,columnNumber:220},this),\\" for modeling time-series data, extending the application of SGVB to optimize global parameters within models, and exploring supervised models that incorporate latent variables to learn complex noise distributions, enhancing model robustness and predictive performance.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:170,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\",lineNumber:1,columnNumber:1},this)}function gn(s={}){let{wrapper:n}=s.components||{};return n?(0,r.jsxDEV)(n,Object.assign({},s,{children:(0,r.jsxDEV)(Ue,s,void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this)}),void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-345938fb-4aed-492c-b781-937700796d54.mdx\\"},this):Ue(s)}var yn=gn;return pn(Nn);})();\\n/*! Bundled license information:\\n\\nreact/cjs/react-jsx-dev-runtime.development.js:\\n  (**\\n   * @license React\\n   * react-jsx-dev-runtime.development.js\\n   *\\n   * Copyright (c) Facebook, Inc. and its affiliates.\\n   *\\n   * This source code is licensed under the MIT license found in the\\n   * LICENSE file in the root directory of this source tree.\\n   *)\\n*/\\n;return Component;"},"_id":"vae/index.mdx","_raw":{"sourceFilePath":"vae/index.mdx","sourceFileName":"index.mdx","sourceFileDir":"vae","contentType":"mdx","flattenedPath":"vae"},"type":"Blog","url":"/blogs/vae","readingTime":{"text":"5 min read","minutes":4.105,"time":246300,"words":821},"toc":[{"level":"three","text":"Citations","slug":"citations"},{"level":"one","text":"Introduction","slug":"introduction"},{"level":"three","text":"Variational Bayesian (Appendix F)","slug":"variational-bayesian-appendix-f"},{"level":"three","text":"Stochastic Gradient Variational Bayes (SGVB)","slug":"stochastic-gradient-variational-bayes-sgvb"},{"level":"three","text":"Auto-Encoding Variational Bayes (AEVB)","slug":"auto-encoding-variational-bayes-aevb"},{"level":"one","text":"Method","slug":"method"},{"level":"three","text":"Problem Scenario","slug":"problem-scenario"},{"level":"three","text":"Method Summary","slug":"method-summary"},{"level":"three","text":"The Variational Bound","slug":"the-variational-bound"},{"level":"three","text":"The SGVB Estimator and AEVB Algorithm","slug":"the-sgvb-estimator-and-aevb-algorithm"},{"level":"three","text":"Reparameterization Trick","slug":"reparameterization-trick"},{"level":"one","text":"Variational Auto-Encoder (VAE)","slug":"variational-auto-encoder-vae"},{"level":"three","text":"Appendix C: MLPs as Probabilistic Encoders and Decoders","slug":"appendix-c-mlps-as-probabilistic-encoders-and-decoders"},{"level":"one","text":"Experiments","slug":"experiments"},{"level":"three","text":"MNIST & Frey Face Datasets","slug":"mnist--frey-face-datasets"},{"level":"three","text":"Likelihood Lower Bound","slug":"likelihood-lower-bound"},{"level":"three","text":"Marginal Likelihood","slug":"marginal-likelihood"},{"level":"three","text":"Visualization of High-Dimensional Data","slug":"visualization-of-high-dimensional-data"},{"level":"one","text":"Conclusion & Future Work","slug":"conclusion--future-work"}]}');

/***/ })

});
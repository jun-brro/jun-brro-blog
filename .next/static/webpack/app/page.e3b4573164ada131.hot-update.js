"use strict";
/*
 * ATTENTION: An "eval-source-map" devtool has been used.
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file with attached SourceMaps in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
self["webpackHotUpdate_N_E"]("app/page",{

/***/ "(app-pages-browser)/./.contentlayer/generated/Blog/vae__index.mdx.json":
/*!**********************************************************!*\
  !*** ./.contentlayer/generated/Blog/vae__index.mdx.json ***!
  \**********************************************************/
/***/ (function(module, __unused_webpack_exports, __webpack_require__) {

module.exports = JSON.parse('{"title":"[Paper Review] VAE (Variational Autoencoders)","publishedAt":"2024-07-13T00:00:00.000Z","updatedAt":"2024-07-13T00:00:00.000Z","description":"Variational Autoencoders (VAEs) employ a probabilistic approach to latent variable modeling, optimizing a variational lower bound to perform efficient approximate posterior inference and learning of generative models with continuous latent variables.","image":{"filePath":"../public/blogs/vae/screenshot.png","relativeFilePath":"../../public/blogs/vae/screenshot.png","format":"png","height":780,"width":1626,"aspectRatio":2.0846153846153848,"blurhashDataUrl":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAD1BMVEX+/v75+Pfy8PH87e3i4O9nI8m+AAAACXBIWXMAABYlAAAWJQFJUiTwAAAAKElEQVR4nE2JQQoAIACDdOv/b46iIi8OB494LSahq9iC37UZtmeyPQEGiwAv5U8KGQAAAABJRU5ErkJggg=="},"isPublished":true,"author":"junbrro","tags":["Deep Learning"],"body":{"raw":"\\nThis post is reviewing the StyleGAN paper.\\n\\n### Citations\\n\\n[VAE : Auto-Encoding Variational Bayes - 논문 리뷰](https://velog.io/@lee9843/VAE-Auto-Encoding-Variational-Bayes-논문-리뷰)\\nThumbnail image: [towardsdatascience](https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2)\\n\\n# Introduction\\n\\nHow can we perform efficient approximate inference and learning with directed probabilistic models whose continuous latent variables and/or parameters have intractable posterior distributions?\\n\\nThe answer lies in **Variational Bayesian** methods, which involve the optimization of approximations to intractable posterior probabilities.\\n\\n### Variational Bayesian (Appendix F)\\n\\nMarginal Likelihood: The combination of KL divergence and the lower bound.\\n\\n![Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fc4cbed7-6b60-40ea-a9c7-c5c9fdb4ba59)\\n\\n![Variational Lower Bound](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4edcf087-3b7e-4073-9063-b705bdbc8f99)\\n\\n**Variational lower bound** to the marginal likelihood:\\n\\n![Variational Lower Bound to Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/102829cb-e02d-49ce-bf67-f8da7b6058cd)\\n\\nMonte Carlo estimate of the variational lower bound:\\n\\n![Monte Carlo Estimate](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c9c61a64-253d-4607-acda-1466ca006569)\\n\\nFor more on [Variational Bayesian methods](https://en.wikipedia.org/wiki/Variational_Bayesian_methods).\\n\\n### Stochastic Gradient Variational Bayes (SGVB)\\n\\nThe **SGVB estimator** is a scalable estimator for variational inference that utilizes stochastic gradients, enabling optimization over large datasets. It facilitates efficient backpropagation through recognition models by approximating gradients, making it useful for efficient approximate posterior inference in almost any model with continuous latent variables and/or parameters.\\n\\n### Auto-Encoding Variational Bayes (AEVB)\\n\\nThe **AEVB algorithm** makes inference and learning particularly efficient by using the SGVB estimator to optimize a recognition model. This approach allows for very efficient approximate posterior inference using simple ancestral sampling, enabling the efficient learning of model parameters without the need for expensive iterative inference schemes like MCMC per datapoint.\\n\\n# Method\\n\\n![Method](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/5d0cf6c3-2880-428d-aec0-4512a9bc64ae)\\n\\n### Problem Scenario\\n\\nConsidering the dataset below:\\n\\n![Dataset Scenario](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4a64183e-7f05-4497-83bc-970973bfb694)\\n\\n1. The latent variable \\\\( z^i \\\\) is generated from the prior distribution \\\\( p\\\\_\\\\theta(z) \\\\).\\n2. The dataset \\\\( x^i \\\\) is generated from the conditional distribution \\\\( p\\\\_\\\\theta(x|z) \\\\).\\n\\n![Dataset Generation](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/e9a6c5fa-d805-425e-872c-f5675c77f4eb)\\n\\nThis approach addresses:\\n\\n1. **Intractability** (cannot compute marginal likelihood)\\n2. **Large datasets** (sampling should be conducted for each data point, which is costly for batch optimization)\\n\\nThe research proposes solutions for three problems:\\n\\n1. **Efficient approximate ML or MAP estimation** for the parameters \\\\( \\\\theta \\\\). These parameters can be of interest themselves for analyzing natural processes and generating artificial data.\\n2. **Efficient approximate posterior inference** of the latent variable \\\\( z \\\\) given an observed value \\\\( x \\\\) for chosen parameters \\\\( \\\\theta \\\\). This is useful for coding or data representation tasks.\\n3. **Efficient approximate marginal inference** of the variable \\\\( x \\\\). This allows for various inference tasks where a prior over \\\\( x \\\\) is required, such as image denoising, inpainting, and super-resolution in computer vision.\\n\\nTo address these problems, the study introduces **a recognition model \\\\( q\\\\_\\\\theta(z|x) \\\\)** as an approximation to the intractable true posterior \\\\( p\\\\_\\\\theta(z|x) \\\\).\\n\\n**METHOD SUMMARY**\\n\\nThe recognition model parameters \\\\( \\\\phi \\\\) are learned together with the generative model parameters \\\\( \\\\theta \\\\). Given a data point \\\\( x \\\\), **a stochastic encoder** produces a distribution (e.g., Gaussian) of possible values for the code \\\\( z \\\\) that could generate \\\\( x \\\\). **A stochastic decoder** \\\\( p\\\\_\\\\theta(x|z) \\\\) then produces a distribution of possible values of \\\\( x \\\\) given \\\\( z \\\\).\\n\\n![Method Summary](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/019bf071-e7d3-4209-950e-6d160210b558)\\n\\n### The Variational Bound\\n\\nMarginal Likelihood \\\\( \\\\log(p\\\\_\\\\theta(x^i)) \\\\):\\n\\n![Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/49db5dae-ee1f-45c4-8c91-85161c6b6b23)\\n\\nRight-hand side (RHS):\\n\\n1. KL divergence of the approximate from the true posterior (non-negative).\\n2. \\\\( L(\\\\theta, \\\\phi; x^i) \\\\), the variational lower bound on the marginal likelihood of datapoint \\\\( i \\\\).\\n\\n![RHS](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fb3ec5c3-f855-4c93-816e-3bf8b3a9a64d)\\n\\n![Variational Bound](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/60b1cc4f-2e9b-4ff9-b0e0-85d35c9252cb)\\n\\nThe objective is to differentiate and optimize the lower bound:\\n\\n![Optimization](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c243f655-27a7-4e8a-8e68-24756dd07c9e)\\n\\nThis corresponds to calculating the probability of \\\\( x \\\\) in Bayes\' theorem, known as the Evidence Lower Bound (ELBO). The loss function is derived from this ELBO.\\n\\n![ELBO](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/6470897e-6044-4b08-b888-eca7da3c6060)\\n\\n### The SGVB Estimator and AEVB Algorithm\\n\\n![SGVB Estimator](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fe40492d-7a49-4cac-ab79-2b049f529a8d)\\n\\n### Reparameterization Trick\\n\\n![Reparameterization Trick](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/a99833ee-ffb3-4001-b151-8025747cff67)\\n\\nTwo assumptions needed to compute regularization:\\n\\n1. The distribution of \\\\( z \\\\) that emerges from passing through the encoder, \\\\( q\\\\_\\\\phi(z|x) \\\\), follows a multivariate normal distribution with a diagonal covariance matrix.\\n2. The assumed distribution of \\\\( z \\\\), the prior \\\\( p(z) \\\\), is that it follows a standard normal distribution with a mean of 0 and a standard deviation of 1.\\n\\nKLD ensures these assumptions are met and facilitates optimization.\\n\\n![KLD Assumptions](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/7f263752-d75d-46fd-be1b-6162b0bc9364)\\n\\nThus, the approach is differentiable, enabling the calculation of regularization.\\n\\n# Variational Auto-Encoder (VAE)\\n\\nThe variational approximate posterior is a multivariate Gaussian with a diagonal covariance structure.\\n\\n![VAE Gaussian](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/8f0c7e31-1e86-4efb-b6fe-4ad6a1f67a55)\\n\\nThe log-likelihood \\\\( \\\\log(p\\\\_\\\\theta(x^i | z^{(i, l)})) \\\\) is modeled as a Bernoulli or Gaussian MLP, depending on the data type.\\n\\n### Appendix C: MLPs as Probabilistic Encoders and Decoders\\n\\n**Bernoulli MLP:**\\n\\n![Bernoulli MLP](https://github.com/jun-br\\n\\nro/deep-learning-paper-review/assets/115399447/45110c25-7f51-4e49-8a9b-ff277db35107)\\n![Bernoulli MLP Details](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2e849014-0a98-4e90-b443-8cfd5170e81f)\\n\\n---\\n\\n**Gaussian MLP:**\\n\\n![Gaussian MLP](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/bede1ba3-a3be-4d91-b61a-d7695a60ae50)\\n![Gaussian MLP Details](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/ffc15c2a-2085-4789-9a0c-9186e0755a60)\\n![Gaussian MLP](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2c1856a6-7090-473e-a357-11d2c57bc6cb)\\n![Gaussian MLP](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/eab9ee56-f060-4e74-9a85-3b893fc0d6e5)\\n\\n# Experiments\\n\\n### MNIST & Frey Face Datasets\\n\\n![Experiments](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/95d86097-c3a2-4450-9745-eb7691b54a28)\\n\\n### Likelihood Lower Bound\\n\\n### Marginal Likelihood\\n\\n![Marginal Likelihood](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2ee19c13-08cb-484e-925d-2dfc15f95450)\\n\\n### Visualization of High-Dimensional Data\\n\\n# Conclusion & Future Work\\n\\n### Conclusion\\n\\n- The **SGVB estimator and AEVB algorithm** significantly improve variational inference for continuous latent variables.\\n- Demonstrated theoretical advantages and experimental results.\\n\\n### Future Work\\n\\n- **Hierarchical Generative Architectures:** Investigating the use of SGVB and AEVB in learning hierarchical generative models, particularly with deep neural networks such as convolutional networks for encoders and decoders.\\n- **Time-Series Models:** Applying these methods to dynamic Bayesian networks for modeling time-series data.\\n- **Global Parameters:** Extending the application of SGVB to optimize global parameters within models.\\n- **Supervised Models with Latent Variables:** Exploring supervised models that incorporate latent variables, aiming to learn complex noise distributions, which can enhance model robustness and predictive performance.\\n","code":"var Component=(()=>{var cn=Object.create;var A=Object.defineProperty;var bn=Object.getOwnPropertyDescriptor;var mn=Object.getOwnPropertyNames;var fn=Object.getPrototypeOf,hn=Object.prototype.hasOwnProperty;var q=(b,n)=>()=>(n||b((n={exports:{}}).exports,n),n.exports),pn=(b,n)=>{for(var g in n)A(b,g,{get:n[g],enumerable:!0})},ve=(b,n,g,j)=>{if(n&&typeof n==\\"object\\"||typeof n==\\"function\\")for(let x of mn(n))!hn.call(b,x)&&x!==g&&A(b,x,{get:()=>n[x],enumerable:!(j=bn(n,x))||j.enumerable});return b};var _n=(b,n,g)=>(g=b!=null?cn(fn(b)):{},ve(n||!b||!b.__esModule?A(g,\\"default\\",{value:b,enumerable:!0}):g,b)),gn=b=>ve(A({},\\"__esModule\\",{value:!0}),b);var De=q((kn,ke)=>{ke.exports=React});var Ge=q(K=>{\\"use strict\\";(function(){\\"use strict\\";var b=De(),n=Symbol.for(\\"react.element\\"),g=Symbol.for(\\"react.portal\\"),j=Symbol.for(\\"react.fragment\\"),x=Symbol.for(\\"react.strict_mode\\"),X=Symbol.for(\\"react.profiler\\"),J=Symbol.for(\\"react.provider\\"),Z=Symbol.for(\\"react.context\\"),E=Symbol.for(\\"react.forward_ref\\"),O=Symbol.for(\\"react.suspense\\"),V=Symbol.for(\\"react.suspense_list\\"),w=Symbol.for(\\"react.memo\\"),B=Symbol.for(\\"react.lazy\\"),we=Symbol.for(\\"react.offscreen\\"),Q=Symbol.iterator,Te=\\"@@iterator\\";function Re(e){if(e===null||typeof e!=\\"object\\")return null;var t=Q&&e[Q]||e[Te];return typeof t==\\"function\\"?t:null}var k=b.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function h(e){{for(var t=arguments.length,a=new Array(t>1?t-1:0),o=1;o<t;o++)a[o-1]=arguments[o];Ce(\\"error\\",e,a)}}function Ce(e,t,a){{var o=k.ReactDebugCurrentFrame,s=o.getStackAddendum();s!==\\"\\"&&(t+=\\"%s\\",a=a.concat([s]));var c=a.map(function(d){return String(d)});c.unshift(\\"Warning: \\"+t),Function.prototype.apply.call(console[e],console,c)}}var Se=!1,Pe=!1,Ae=!1,Oe=!1,Ve=!1,ee;ee=Symbol.for(\\"react.module.reference\\");function Be(e){return!!(typeof e==\\"string\\"||typeof e==\\"function\\"||e===j||e===X||Ve||e===x||e===O||e===V||Oe||e===we||Se||Pe||Ae||typeof e==\\"object\\"&&e!==null&&(e.$$typeof===B||e.$$typeof===w||e.$$typeof===J||e.$$typeof===Z||e.$$typeof===E||e.$$typeof===ee||e.getModuleId!==void 0))}function Me(e,t,a){var o=e.displayName;if(o)return o;var s=t.displayName||t.name||\\"\\";return s!==\\"\\"?a+\\"(\\"+s+\\")\\":a}function ne(e){return e.displayName||\\"Context\\"}function N(e){if(e==null)return null;if(typeof e.tag==\\"number\\"&&h(\\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\\"),typeof e==\\"function\\")return e.displayName||e.name||null;if(typeof e==\\"string\\")return e;switch(e){case j:return\\"Fragment\\";case g:return\\"Portal\\";case X:return\\"Profiler\\";case x:return\\"StrictMode\\";case O:return\\"Suspense\\";case V:return\\"SuspenseList\\"}if(typeof e==\\"object\\")switch(e.$$typeof){case Z:var t=e;return ne(t)+\\".Consumer\\";case J:var a=e;return ne(a._context)+\\".Provider\\";case E:return Me(e,e.render,\\"ForwardRef\\");case w:var o=e.displayName||null;return o!==null?o:N(e.type)||\\"Memo\\";case B:{var s=e,c=s._payload,d=s._init;try{return N(d(c))}catch{return null}}}return null}var v=Object.assign,U=0,re,te,ie,ae,oe,ue,de;function le(){}le.__reactDisabledLog=!0;function Le(){{if(U===0){re=console.log,te=console.info,ie=console.warn,ae=console.error,oe=console.group,ue=console.groupCollapsed,de=console.groupEnd;var e={configurable:!0,enumerable:!0,value:le,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}U++}}function Ie(){{if(U--,U===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:v({},e,{value:re}),info:v({},e,{value:te}),warn:v({},e,{value:ie}),error:v({},e,{value:ae}),group:v({},e,{value:oe}),groupCollapsed:v({},e,{value:ue}),groupEnd:v({},e,{value:de})})}U<0&&h(\\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\\")}}var M=k.ReactCurrentDispatcher,L;function T(e,t,a){{if(L===void 0)try{throw Error()}catch(s){var o=s.stack.trim().match(/\\\\n( *(at )?)/);L=o&&o[1]||\\"\\"}return`\\n`+L+e}}var I=!1,R;{var Fe=typeof WeakMap==\\"function\\"?WeakMap:Map;R=new Fe}function se(e,t){if(!e||I)return\\"\\";{var a=R.get(e);if(a!==void 0)return a}var o;I=!0;var s=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var c;c=M.current,M.current=null,Le();try{if(t){var d=function(){throw Error()};if(Object.defineProperty(d.prototype,\\"props\\",{set:function(){throw Error()}}),typeof Reflect==\\"object\\"&&Reflect.construct){try{Reflect.construct(d,[])}catch(y){o=y}Reflect.construct(e,[],d)}else{try{d.call()}catch(y){o=y}e.call(d.prototype)}}else{try{throw Error()}catch(y){o=y}e()}}catch(y){if(y&&o&&typeof y.stack==\\"string\\"){for(var u=y.stack.split(`\\n`),p=o.stack.split(`\\n`),m=u.length-1,f=p.length-1;m>=1&&f>=0&&u[m]!==p[f];)f--;for(;m>=1&&f>=0;m--,f--)if(u[m]!==p[f]){if(m!==1||f!==1)do if(m--,f--,f<0||u[m]!==p[f]){var _=`\\n`+u[m].replace(\\" at new \\",\\" at \\");return e.displayName&&_.includes(\\"<anonymous>\\")&&(_=_.replace(\\"<anonymous>\\",e.displayName)),typeof e==\\"function\\"&&R.set(e,_),_}while(m>=1&&f>=0);break}}}finally{I=!1,M.current=c,Ie(),Error.prepareStackTrace=s}var G=e?e.displayName||e.name:\\"\\",je=G?T(G):\\"\\";return typeof e==\\"function\\"&&R.set(e,je),je}function ze(e,t,a){return se(e,!1)}function We(e){var t=e.prototype;return!!(t&&t.isReactComponent)}function C(e,t,a){if(e==null)return\\"\\";if(typeof e==\\"function\\")return se(e,We(e));if(typeof e==\\"string\\")return T(e);switch(e){case O:return T(\\"Suspense\\");case V:return T(\\"SuspenseList\\")}if(typeof e==\\"object\\")switch(e.$$typeof){case E:return ze(e.render);case w:return C(e.type,t,a);case B:{var o=e,s=o._payload,c=o._init;try{return C(c(s),t,a)}catch{}}}return\\"\\"}var S=Object.prototype.hasOwnProperty,ce={},be=k.ReactDebugCurrentFrame;function P(e){if(e){var t=e._owner,a=C(e.type,e._source,t?t.type:null);be.setExtraStackFrame(a)}else be.setExtraStackFrame(null)}function Ye(e,t,a,o,s){{var c=Function.call.bind(S);for(var d in e)if(c(e,d)){var u=void 0;try{if(typeof e[d]!=\\"function\\"){var p=Error((o||\\"React class\\")+\\": \\"+a+\\" type `\\"+d+\\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\\"+typeof e[d]+\\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\\");throw p.name=\\"Invariant Violation\\",p}u=e[d](t,d,o,a,null,\\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\\")}catch(m){u=m}u&&!(u instanceof Error)&&(P(s),h(\\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\\",o||\\"React class\\",a,d,typeof u),P(null)),u instanceof Error&&!(u.message in ce)&&(ce[u.message]=!0,P(s),h(\\"Failed %s type: %s\\",a,u.message),P(null))}}}var $e=Array.isArray;function F(e){return $e(e)}function qe(e){{var t=typeof Symbol==\\"function\\"&&Symbol.toStringTag,a=t&&e[Symbol.toStringTag]||e.constructor.name||\\"Object\\";return a}}function Ke(e){try{return me(e),!1}catch{return!0}}function me(e){return\\"\\"+e}function fe(e){if(Ke(e))return h(\\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\\",qe(e)),me(e)}var H=k.ReactCurrentOwner,Xe={key:!0,ref:!0,__self:!0,__source:!0},he,pe,z;z={};function Je(e){if(S.call(e,\\"ref\\")){var t=Object.getOwnPropertyDescriptor(e,\\"ref\\").get;if(t&&t.isReactWarning)return!1}return e.ref!==void 0}function Ze(e){if(S.call(e,\\"key\\")){var t=Object.getOwnPropertyDescriptor(e,\\"key\\").get;if(t&&t.isReactWarning)return!1}return e.key!==void 0}function Qe(e,t){if(typeof e.ref==\\"string\\"&&H.current&&t&&H.current.stateNode!==t){var a=N(H.current.type);z[a]||(h(\'Component \\"%s\\" contains the string ref \\"%s\\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref\',N(H.current.type),e.ref),z[a]=!0)}}function en(e,t){{var a=function(){he||(he=!0,h(\\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",t))};a.isReactWarning=!0,Object.defineProperty(e,\\"key\\",{get:a,configurable:!0})}}function nn(e,t){{var a=function(){pe||(pe=!0,h(\\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\\",t))};a.isReactWarning=!0,Object.defineProperty(e,\\"ref\\",{get:a,configurable:!0})}}var rn=function(e,t,a,o,s,c,d){var u={$$typeof:n,type:e,key:t,ref:a,props:d,_owner:c};return u._store={},Object.defineProperty(u._store,\\"validated\\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(u,\\"_self\\",{configurable:!1,enumerable:!1,writable:!1,value:o}),Object.defineProperty(u,\\"_source\\",{configurable:!1,enumerable:!1,writable:!1,value:s}),Object.freeze&&(Object.freeze(u.props),Object.freeze(u)),u};function tn(e,t,a,o,s){{var c,d={},u=null,p=null;a!==void 0&&(fe(a),u=\\"\\"+a),Ze(t)&&(fe(t.key),u=\\"\\"+t.key),Je(t)&&(p=t.ref,Qe(t,s));for(c in t)S.call(t,c)&&!Xe.hasOwnProperty(c)&&(d[c]=t[c]);if(e&&e.defaultProps){var m=e.defaultProps;for(c in m)d[c]===void 0&&(d[c]=m[c])}if(u||p){var f=typeof e==\\"function\\"?e.displayName||e.name||\\"Unknown\\":e;u&&en(d,f),p&&nn(d,f)}return rn(e,u,p,s,o,H.current,d)}}var W=k.ReactCurrentOwner,_e=k.ReactDebugCurrentFrame;function D(e){if(e){var t=e._owner,a=C(e.type,e._source,t?t.type:null);_e.setExtraStackFrame(a)}else _e.setExtraStackFrame(null)}var Y;Y=!1;function $(e){return typeof e==\\"object\\"&&e!==null&&e.$$typeof===n}function ge(){{if(W.current){var e=N(W.current.type);if(e)return`\\n\\nCheck the render method of \\\\``+e+\\"`.\\"}return\\"\\"}}function an(e){{if(e!==void 0){var t=e.fileName.replace(/^.*[\\\\\\\\\\\\/]/,\\"\\"),a=e.lineNumber;return`\\n\\nCheck your code at `+t+\\":\\"+a+\\".\\"}return\\"\\"}}var Ne={};function on(e){{var t=ge();if(!t){var a=typeof e==\\"string\\"?e:e.displayName||e.name;a&&(t=`\\n\\nCheck the top-level render call using <`+a+\\">.\\")}return t}}function ye(e,t){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var a=on(t);if(Ne[a])return;Ne[a]=!0;var o=\\"\\";e&&e._owner&&e._owner!==W.current&&(o=\\" It was passed a child from \\"+N(e._owner.type)+\\".\\"),D(e),h(\'Each child in a list should have a unique \\"key\\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.\',a,o),D(null)}}function xe(e,t){{if(typeof e!=\\"object\\")return;if(F(e))for(var a=0;a<e.length;a++){var o=e[a];$(o)&&ye(o,t)}else if($(e))e._store&&(e._store.validated=!0);else if(e){var s=Re(e);if(typeof s==\\"function\\"&&s!==e.entries)for(var c=s.call(e),d;!(d=c.next()).done;)$(d.value)&&ye(d.value,t)}}}function un(e){{var t=e.type;if(t==null||typeof t==\\"string\\")return;var a;if(typeof t==\\"function\\")a=t.propTypes;else if(typeof t==\\"object\\"&&(t.$$typeof===E||t.$$typeof===w))a=t.propTypes;else return;if(a){var o=N(t);Ye(a,e.props,\\"prop\\",o,e)}else if(t.PropTypes!==void 0&&!Y){Y=!0;var s=N(t);h(\\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\\",s||\\"Unknown\\")}typeof t.getDefaultProps==\\"function\\"&&!t.getDefaultProps.isReactClassApproved&&h(\\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\\")}}function dn(e){{for(var t=Object.keys(e.props),a=0;a<t.length;a++){var o=t[a];if(o!==\\"children\\"&&o!==\\"key\\"){D(e),h(\\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\\",o),D(null);break}}e.ref!==null&&(D(e),h(\\"Invalid attribute `ref` supplied to `React.Fragment`.\\"),D(null))}}function ln(e,t,a,o,s,c){{var d=Be(e);if(!d){var u=\\"\\";(e===void 0||typeof e==\\"object\\"&&e!==null&&Object.keys(e).length===0)&&(u+=\\" You likely forgot to export your component from the file it\'s defined in, or you might have mixed up default and named imports.\\");var p=an(s);p?u+=p:u+=ge();var m;e===null?m=\\"null\\":F(e)?m=\\"array\\":e!==void 0&&e.$$typeof===n?(m=\\"<\\"+(N(e.type)||\\"Unknown\\")+\\" />\\",u=\\" Did you accidentally export a JSX literal instead of a component?\\"):m=typeof e,h(\\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\\",m,u)}var f=tn(e,t,a,s,c);if(f==null)return f;if(d){var _=t.children;if(_!==void 0)if(o)if(F(_)){for(var G=0;G<_.length;G++)xe(_[G],e);Object.freeze&&Object.freeze(_)}else h(\\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\\");else xe(_,e)}return e===j?dn(f):un(f),f}}var sn=ln;K.Fragment=j,K.jsxDEV=sn})()});var He=q((Gn,Ue)=>{\\"use strict\\";Ue.exports=Ge()});var jn={};pn(jn,{default:()=>xn,frontmatter:()=>Nn});var r=_n(He()),Nn={title:\\"[Paper Review] VAE (Variational Autoencoders)\\",description:\\"Variational Autoencoders (VAEs) employ a probabilistic approach to latent variable modeling, optimizing a variational lower bound to perform efficient approximate posterior inference and learning of generative models with continuous latent variables.\\",image:\\"../../public/blogs/vae/screenshot.png\\",publishedAt:\\"2024-07-13\\",updatedAt:\\"2024-07-13\\",author:\\"junbrro\\",isPublished:!0,tags:[\\"Deep Learning\\"]};function Ee(b){let n=Object.assign({p:\\"p\\",h3:\\"h3\\",a:\\"a\\",span:\\"span\\",h1:\\"h1\\",strong:\\"strong\\",img:\\"img\\",ol:\\"ol\\",li:\\"li\\",hr:\\"hr\\",ul:\\"ul\\"},b.components);return(0,r.jsxDEV)(r.Fragment,{children:[(0,r.jsxDEV)(n.p,{children:\\"This post is reviewing the StyleGAN paper.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:13,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"citations\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#citations\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Citations\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:15,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[(0,r.jsxDEV)(n.a,{href:\\"https://velog.io/@lee9843/VAE-Auto-Encoding-Variational-Bayes-%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0\\",children:\\"VAE : Auto-Encoding Variational Bayes - \\\\uB17C\\\\uBB38 \\\\uB9AC\\\\uBDF0\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:17,columnNumber:1},this),`\\nThumbnail image: `,(0,r.jsxDEV)(n.a,{href:\\"https://towardsdatascience.com/difference-between-autoencoder-ae-and-variational-autoencoder-vae-ed7be1c038f2\\",children:\\"towardsdatascience\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:18,columnNumber:18},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:17,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"introduction\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#introduction\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Introduction\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:20,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"How can we perform efficient approximate inference and learning with directed probabilistic models whose continuous latent variables and/or parameters have intractable posterior distributions?\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:22,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The answer lies in \\",(0,r.jsxDEV)(n.strong,{children:\\"Variational Bayesian\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:24,columnNumber:20},this),\\" methods, which involve the optimization of approximations to intractable posterior probabilities.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:24,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"variational-bayesian-appendix-f\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#variational-bayesian-appendix-f\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Variational Bayesian (Appendix F)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:26,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Marginal Likelihood: The combination of KL divergence and the lower bound.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:28,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fc4cbed7-6b60-40ea-a9c7-c5c9fdb4ba59\\",alt:\\"Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:30,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:30,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4edcf087-3b7e-4073-9063-b705bdbc8f99\\",alt:\\"Variational Lower Bound\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:32,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:32,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Variational lower bound\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:34,columnNumber:1},this),\\" to the marginal likelihood:\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:34,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/102829cb-e02d-49ce-bf67-f8da7b6058cd\\",alt:\\"Variational Lower Bound to Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:36,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:36,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Monte Carlo estimate of the variational lower bound:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:38,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c9c61a64-253d-4607-acda-1466ca006569\\",alt:\\"Monte Carlo Estimate\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:40,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:40,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"For more on \\",(0,r.jsxDEV)(n.a,{href:\\"https://en.wikipedia.org/wiki/Variational_Bayesian_methods\\",children:\\"Variational Bayesian methods\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:42,columnNumber:13},this),\\".\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:42,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"stochastic-gradient-variational-bayes-sgvb\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#stochastic-gradient-variational-bayes-sgvb\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Stochastic Gradient Variational Bayes (SGVB)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:44,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The \\",(0,r.jsxDEV)(n.strong,{children:\\"SGVB estimator\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:46,columnNumber:5},this),\\" is a scalable estimator for variational inference that utilizes stochastic gradients, enabling optimization over large datasets. It facilitates efficient backpropagation through recognition models by approximating gradients, making it useful for efficient approximate posterior inference in almost any model with continuous latent variables and/or parameters.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:46,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"auto-encoding-variational-bayes-aevb\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#auto-encoding-variational-bayes-aevb\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Auto-Encoding Variational Bayes (AEVB)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:48,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The \\",(0,r.jsxDEV)(n.strong,{children:\\"AEVB algorithm\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:50,columnNumber:5},this),\\" makes inference and learning particularly efficient by using the SGVB estimator to optimize a recognition model. This approach allows for very efficient approximate posterior inference using simple ancestral sampling, enabling the efficient learning of model parameters without the need for expensive iterative inference schemes like MCMC per datapoint.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:50,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"method\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#method\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Method\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:52,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/5d0cf6c3-2880-428d-aec0-4512a9bc64ae\\",alt:\\"Method\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:54,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:54,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"problem-scenario\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#problem-scenario\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Problem Scenario\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:56,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Considering the dataset below:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:58,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/4a64183e-7f05-4497-83bc-970973bfb694\\",alt:\\"Dataset Scenario\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:60,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:60,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The latent variable ( z^i ) is generated from the prior distribution ( p_\\\\\\\\theta(z) ).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:62,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The dataset ( x^i ) is generated from the conditional distribution ( p_\\\\\\\\theta(x|z) ).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:63,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:62,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/e9a6c5fa-d805-425e-872c-f5675c77f4eb\\",alt:\\"Dataset Generation\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:65,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:65,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"This approach addresses:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:67,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Intractability\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:69,columnNumber:4},this),\\" (cannot compute marginal likelihood)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:69,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Large datasets\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:70,columnNumber:4},this),\\" (sampling should be conducted for each data point, which is costly for batch optimization)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:70,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:69,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"The research proposes solutions for three problems:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:72,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Efficient approximate ML or MAP estimation\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:74,columnNumber:4},this),\\" for the parameters ( \\\\\\\\theta ). These parameters can be of interest themselves for analyzing natural processes and generating artificial data.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:74,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Efficient approximate posterior inference\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:75,columnNumber:4},this),\\" of the latent variable ( z ) given an observed value ( x ) for chosen parameters ( \\\\\\\\theta ). This is useful for coding or data representation tasks.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:75,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Efficient approximate marginal inference\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:76,columnNumber:4},this),\\" of the variable ( x ). This allows for various inference tasks where a prior over ( x ) is required, such as image denoising, inpainting, and super-resolution in computer vision.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:76,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:74,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"To address these problems, the study introduces \\",(0,r.jsxDEV)(n.strong,{children:\\"a recognition model ( q_\\\\\\\\theta(z|x) )\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:78,columnNumber:49},this),\\" as an approximation to the intractable true posterior ( p_\\\\\\\\theta(z|x) ).\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:78,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.strong,{children:\\"METHOD SUMMARY\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:80,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:80,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The recognition model parameters ( \\\\\\\\phi ) are learned together with the generative model parameters ( \\\\\\\\theta ). Given a data point ( x ), \\",(0,r.jsxDEV)(n.strong,{children:\\"a stochastic encoder\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:82,columnNumber:145},this),\\" produces a distribution (e.g., Gaussian) of possible values for the code ( z ) that could generate ( x ). \\",(0,r.jsxDEV)(n.strong,{children:\\"A stochastic decoder\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:82,columnNumber:280},this),\\" ( p_\\\\\\\\theta(x|z) ) then produces a distribution of possible values of ( x ) given ( z ).\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:82,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/019bf071-e7d3-4209-950e-6d160210b558\\",alt:\\"Method Summary\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:84,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:84,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"the-variational-bound\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#the-variational-bound\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"The Variational Bound\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:86,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Marginal Likelihood ( \\\\\\\\log(p_\\\\\\\\theta(x^i)) ):\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:88,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/49db5dae-ee1f-45c4-8c91-85161c6b6b23\\",alt:\\"Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:90,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:90,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Right-hand side (RHS):\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:92,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:\\"KL divergence of the approximate from the true posterior (non-negative).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:94,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:\\"( L(\\\\\\\\theta, \\\\\\\\phi; x^i) ), the variational lower bound on the marginal likelihood of datapoint ( i ).\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:95,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:94,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fb3ec5c3-f855-4c93-816e-3bf8b3a9a64d\\",alt:\\"RHS\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:97,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:97,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/60b1cc4f-2e9b-4ff9-b0e0-85d35c9252cb\\",alt:\\"Variational Bound\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:99,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:99,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"The objective is to differentiate and optimize the lower bound:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:101,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c243f655-27a7-4e8a-8e68-24756dd07c9e\\",alt:\\"Optimization\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:103,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:103,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"This corresponds to calculating the probability of ( x ) in Bayes\' theorem, known as the Evidence Lower Bound (ELBO). The loss function is derived from this ELBO.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:105,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/6470897e-6044-4b08-b888-eca7da3c6060\\",alt:\\"ELBO\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:107,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:107,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"the-sgvb-estimator-and-aevb-algorithm\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#the-sgvb-estimator-and-aevb-algorithm\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"The SGVB Estimator and AEVB Algorithm\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:109,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/fe40492d-7a49-4cac-ab79-2b049f529a8d\\",alt:\\"SGVB Estimator\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:111,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:111,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"reparameterization-trick\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#reparameterization-trick\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Reparameterization Trick\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:113,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/a99833ee-ffb3-4001-b151-8025747cff67\\",alt:\\"Reparameterization Trick\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:115,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:115,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Two assumptions needed to compute regularization:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:117,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ol,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The distribution of ( z ) that emerges from passing through the encoder, ( q_\\\\\\\\phi(z|x) ), follows a multivariate normal distribution with a diagonal covariance matrix.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:119,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:\\"The assumed distribution of ( z ), the prior ( p(z) ), is that it follows a standard normal distribution with a mean of 0 and a standard deviation of 1.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:120,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:119,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"KLD ensures these assumptions are met and facilitates optimization.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:122,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/7f263752-d75d-46fd-be1b-6162b0bc9364\\",alt:\\"KLD Assumptions\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:124,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:124,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"Thus, the approach is differentiable, enabling the calculation of regularization.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:126,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"variational-auto-encoder-vae\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#variational-auto-encoder-vae\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Variational Auto-Encoder (VAE)\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:128,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:\\"The variational approximate posterior is a multivariate Gaussian with a diagonal covariance structure.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:130,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/8f0c7e31-1e86-4efb-b6fe-4ad6a1f67a55\\",alt:\\"VAE Gaussian\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:132,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:132,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"The log-likelihood ( \\\\\\\\log(p_\\\\\\\\theta(x^i | z^\\",(i,l),\\")) ) is modeled as a Bernoulli or Gaussian MLP, depending on the data type.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:134,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"appendix-c-mlps-as-probabilistic-encoders-and-decoders\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#appendix-c-mlps-as-probabilistic-encoders-and-decoders\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Appendix C: MLPs as Probabilistic Encoders and Decoders\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:136,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.strong,{children:\\"Bernoulli MLP:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:138,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:138,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[\\"![Bernoulli MLP](\\",(0,r.jsxDEV)(n.a,{href:\\"https://github.com/jun-br\\",children:\\"https://github.com/jun-br\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:140,columnNumber:18},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:140,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[`ro/deep-learning-paper-review/assets/115399447/45110c25-7f51-4e49-8a9b-ff277db35107)\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2e849014-0a98-4e90-b443-8cfd5170e81f\\",alt:\\"Bernoulli MLP Details\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:143,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:142,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.hr,{},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:145,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.strong,{children:\\"Gaussian MLP:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:147,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:147,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:[(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/bede1ba3-a3be-4d91-b61a-d7695a60ae50\\",alt:\\"Gaussian MLP\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:149,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/ffc15c2a-2085-4789-9a0c-9186e0755a60\\",alt:\\"Gaussian MLP Details\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:150,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2c1856a6-7090-473e-a357-11d2c57bc6cb\\",alt:\\"Gaussian MLP\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:151,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/eab9ee56-f060-4e74-9a85-3b893fc0d6e5\\",alt:\\"Gaussian MLP\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:152,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:149,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"experiments\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#experiments\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Experiments\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:154,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"mnist--frey-face-datasets\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#mnist--frey-face-datasets\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"MNIST & Frey Face Datasets\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:156,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/95d86097-c3a2-4450-9745-eb7691b54a28\\",alt:\\"Experiments\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:158,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:158,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"likelihood-lower-bound\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#likelihood-lower-bound\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Likelihood Lower Bound\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:160,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"marginal-likelihood\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#marginal-likelihood\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Marginal Likelihood\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:162,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.p,{children:(0,r.jsxDEV)(n.img,{src:\\"https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2ee19c13-08cb-484e-925d-2dfc15f95450\\",alt:\\"Marginal Likelihood\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:164,columnNumber:1},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:164,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"visualization-of-high-dimensional-data\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#visualization-of-high-dimensional-data\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Visualization of High-Dimensional Data\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:166,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h1,{id:\\"conclusion--future-work\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#conclusion--future-work\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Conclusion & Future Work\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:168,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"conclusion\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#conclusion\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Conclusion\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:170,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ul,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:[\\"The \\",(0,r.jsxDEV)(n.strong,{children:\\"SGVB estimator and AEVB algorithm\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:172,columnNumber:7},this),\\" significantly improve variational inference for continuous latent variables.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:172,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:\\"Demonstrated theoretical advantages and experimental results.\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:173,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:172,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.h3,{id:\\"future-work\\",children:[(0,r.jsxDEV)(n.a,{\\"aria-hidden\\":\\"true\\",tabIndex:\\"-1\\",href:\\"#future-work\\",children:(0,r.jsxDEV)(n.span,{className:\\"icon icon-link\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this),\\"Future Work\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:175,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.ul,{children:[`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Hierarchical Generative Architectures:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:177,columnNumber:3},this),\\" Investigating the use of SGVB and AEVB in learning hierarchical generative models, particularly with deep neural networks such as convolutional networks for encoders and decoders.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:177,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Time-Series Models:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:178,columnNumber:3},this),\\" Applying these methods to dynamic Bayesian networks for modeling time-series data.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:178,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Global Parameters:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:179,columnNumber:3},this),\\" Extending the application of SGVB to optimize global parameters within models.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:179,columnNumber:1},this),`\\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\\"Supervised Models with Latent Variables:\\"},void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:180,columnNumber:3},this),\\" Exploring supervised models that incorporate latent variables, aiming to learn complex noise distributions, which can enhance model robustness and predictive performance.\\"]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:180,columnNumber:1},this),`\\n`]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:177,columnNumber:1},this)]},void 0,!0,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\",lineNumber:1,columnNumber:1},this)}function yn(b={}){let{wrapper:n}=b.components||{};return n?(0,r.jsxDEV)(n,Object.assign({},b,{children:(0,r.jsxDEV)(Ee,b,void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this)}),void 0,!1,{fileName:\\"/Users/junhyeongpark/Documents/GitHub/jun-brro-blog/content/_mdx_bundler_entry_point-e90c3d01-570a-4b15-8076-8de8efa6c213.mdx\\"},this):Ee(b)}var xn=yn;return gn(jn);})();\\n/*! Bundled license information:\\n\\nreact/cjs/react-jsx-dev-runtime.development.js:\\n  (**\\n   * @license React\\n   * react-jsx-dev-runtime.development.js\\n   *\\n   * Copyright (c) Facebook, Inc. and its affiliates.\\n   *\\n   * This source code is licensed under the MIT license found in the\\n   * LICENSE file in the root directory of this source tree.\\n   *)\\n*/\\n;return Component;"},"_id":"vae/index.mdx","_raw":{"sourceFilePath":"vae/index.mdx","sourceFileName":"index.mdx","sourceFileDir":"vae","contentType":"mdx","flattenedPath":"vae"},"type":"Blog","url":"/blogs/vae","readingTime":{"text":"5 min read","minutes":4.485,"time":269100,"words":897},"toc":[{"level":"three","text":"Citations","slug":"citations"},{"level":"one","text":"Introduction","slug":"introduction"},{"level":"three","text":"Variational Bayesian (Appendix F)","slug":"variational-bayesian-appendix-f"},{"level":"three","text":"Stochastic Gradient Variational Bayes (SGVB)","slug":"stochastic-gradient-variational-bayes-sgvb"},{"level":"three","text":"Auto-Encoding Variational Bayes (AEVB)","slug":"auto-encoding-variational-bayes-aevb"},{"level":"one","text":"Method","slug":"method"},{"level":"three","text":"Problem Scenario","slug":"problem-scenario"},{"level":"three","text":"The Variational Bound","slug":"the-variational-bound"},{"level":"three","text":"The SGVB Estimator and AEVB Algorithm","slug":"the-sgvb-estimator-and-aevb-algorithm"},{"level":"three","text":"Reparameterization Trick","slug":"reparameterization-trick"},{"level":"one","text":"Variational Auto-Encoder (VAE)","slug":"variational-auto-encoder-vae"},{"level":"three","text":"Appendix C: MLPs as Probabilistic Encoders and Decoders","slug":"appendix-c-mlps-as-probabilistic-encoders-and-decoders"},{"level":"one","text":"Experiments","slug":"experiments"},{"level":"three","text":"MNIST & Frey Face Datasets","slug":"mnist--frey-face-datasets"},{"level":"three","text":"Likelihood Lower Bound","slug":"likelihood-lower-bound"},{"level":"three","text":"Marginal Likelihood","slug":"marginal-likelihood"},{"level":"three","text":"Visualization of High-Dimensional Data","slug":"visualization-of-high-dimensional-data"},{"level":"one","text":"Conclusion & Future Work","slug":"conclusion--future-work"},{"level":"three","text":"Conclusion","slug":"conclusion"},{"level":"three","text":"Future Work","slug":"future-work"}]}');

/***/ })

});
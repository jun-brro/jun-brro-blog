---
title: "[Paper Review] StyleGAN (Style Generative Adversarial Nets)"
description: "StyleGAN introduces a novel architecture for generative adversarial networks that separates high-level attributes from stochastic variation, enabling fine-grained control over the generated images through an intermediate latent space and adaptive instance normalization."
image: "../../public/blogs/stylegan/screenshot.png"
publishedAt: "2024-07-13"
updatedAt: "2024-07-13"
author: "junbrro"
isPublished: true
tags:
  - Deep Learning
---

This post is reviewing the StyleGAN paper.

# PGGAN: Progressive Growing of GANs

![PGGAN Diagram](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/c0838342-f24f-4c0d-bec3-43061057e24b)

**Progressive training** starts with low-resolution images and gradually increases the resolution by adding layers. This technique enhances the stability and quality of the images generated by the GAN. By progressively growing the GAN, it generates high-resolution, high-quality images and reduces instability in training high-resolution images. The **adaptive learning rate** adjusts for each layer, with new layers having higher rates, while **pixelwise feature vector normalization** in the generator ensures stable training. This method effectively captures fine details, making the generated images more realistic and has proven to be flexible across various domains, not just faces. The influence of PGGAN on subsequent GAN research is significant, promoting progressive training and high-resolution generation.

# Style-based Generator: StyleGAN

![StyleGAN Diagram](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/808eb66e-c516-4201-aacd-99b0e362702d)

Traditional GANs receive input through the input layer, but **StyleGAN omits this layer** and instead uses a nonlinear mapping from a learned constant to an **intermediate latent space W**. In this process, the latent code z from the input latent space Z is transformed into the intermediate latent space W through a nonlinear mapping network f, implemented using an 8-layer MLP. The converted vector w is then specialized into a **spatially invariant style y** through learned affine transformations. This style y controls the **Adaptive Instance Normalization (AdaIN)** at each convolution layer of the generator.

![AdaIN](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/e57716fe-908c-45b7-b0a1-2b7138bf0d57)
![AdaIN Operation](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/bf6ee61d-e861-4476-a3be-cf9a630d9afd)

The **AdaIN operation** normalizes each feature map separately and then scales and biases it using the corresponding scalar components of style y. For each feature map, AdaIN adjusts its scale and shifts based on the style information encoded in y. This process allows the generator to apply complex style patterns to the generated images, influencing everything from color schemes to textures in a coherent and controlled manner. The use of a spatially invariant style ensures the generated image maintains a consistent style throughout.

To enhance the generator's ability to create stochastic details, **explicit noise inputs** are implemented. These inputs are single-channel images filled with uncorrelated Gaussian noise. Each layer of the synthesis network receives its own unique noise image, which is scaled for each feature map based on learned scaling factors and then added to the output of its respective convolution layer.

![Noise Input](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/f23ed6e1-a98e-447c-b603-2e707f8b1ed7)

### Quality of Generated Images

The improvement in image quality with StyleGAN is demonstrated by the reduction in **FID (Frechet Inception Distances)** across different generator architectures for the CELEBA-HQ and the new FFHQ datasets. This advancement and the enhancement of image resolution represent significant strides in GAN research.

### Prior Art

Previous research focused heavily on **improving the discriminator**, using techniques such as multiple discriminators, multi-resolution discrimination, and self-attention mechanisms. For the generator, research concentrated on fine-tuning the distribution in the input latent space or shaping the latent space, with conditional generators exploring new methods of feeding class identifiers through several layers of the generator.

# Properties of the Style-based Generator

### Style Mixing

![Style Mixing](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/bb33d2d1-e774-4e62-9f6d-f07bd9e689a5)

**Mixing Regularization:** During the learning process, StyleGAN uses ‘mixing’ as a form of regularization. By mixing styles during training, the model learns to handle a variety of style combinations more effectively. This regularization improves the model's robustness and generalization capabilities.

**Style Mixing:** During testing, the same mixing process allows for the combination of styles from two different images. This feature enables the generation of images that blend characteristics from multiple source images, resulting in unique and diverse outputs.

### Stochastic Variation

![Stochastic Variation 1](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/20f20554-eee4-495f-a5c9-0ee3018e759f)
![Stochastic Variation 2](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/2a99646c-5964-4536-aa8c-f6d6ece78598)

**Noise Inputs and Stochastic Details:** By adding explicit noise inputs to each layer of the synthesis network, StyleGAN can generate stochastic details in the images. These noise inputs are single-channel images filled with uncorrelated Gaussian noise, scaled by learned factors and added to the output of their respective convolution layers. This process allows the generator to introduce fine-grained details, such as hair strands or skin texture, enhancing the realism of the generated images.

### Separation of Global Effects from Stochasticity

In StyleGAN, the model can distinguish between global effects and stochastic details. Global effects, such as the overall shape and structure of the generated objects, are controlled by the style vectors. In contrast, stochastic variations, like the fine details and textures, are influenced by the noise inputs. This separation allows for better control and manipulation of the generated images, enabling users to tweak global features without affecting fine details and vice versa.

# Disentanglement Studies

### Perceptual Path Length

![Perceptual Path Length 1](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/ad13296e-8e76-466b-8ee5-0c3b8a797224)
![Perceptual Path Length 2](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/298a1098-4644-43e0-b161-b5191c2e8fef)
![Perceptual Path Length 3](https://github.com/jun-brro/deep-learning-paper-review/assets/115399447/a8571e11-5ea9-4f18-816d-f8cc21fa54e5)

**Perceptual Path Length:** This metric measures the perceptual difference between images as they move through the latent space. A lower perceptual path length indicates smoother transitions and better disentanglement of the latent space, meaning that changes in the latent vectors correspond to meaningful changes in the generated images.

### Linear Separability

StyleGAN’s architecture improves the **linear separability** of the latent space, which makes it easier to isolate and manipulate individual features of the generated images. This characteristic is particularly valuable for applications requiring specific attribute modifications, such as changing the hair color or facial expression in generated portraits.

# Conclusion

StyleGAN represents a significant advancement in GAN technology. By introducing a style-based generator and progressive growing, it achieves high-resolution, high-quality image generation with improved stability. The model's ability to mix styles, generate stochastic details, and separate global effects from fine details allows for unprecedented control and flexibility in image generation. The improvements in perceptual path length and linear separability further enhance the quality and usability of the generated images, making StyleGAN a powerful tool in the field of generative models.
